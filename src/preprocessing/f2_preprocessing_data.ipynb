{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T17:01:45.010768Z",
     "start_time": "2020-09-12T17:01:44.967892Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c778229cd0dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "# ============================================\n",
    "# clean tranaction price df\n",
    "# ============================================\n",
    "def clean_transaction_price():\n",
    "    # load raw data:\n",
    "    df = pd.read_json('../data/raw/price.jl', lines=True,orient='records').drop_duplicates()\n",
    "    df = df.loc[~df.district.isnull()]\n",
    "    print(f'Orignal df transaction price: {df.shape}')\n",
    "    \n",
    "    # clean district name:\n",
    "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
    "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
    "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
    "    df['district'] = df['district'].str.title()\n",
    "    \n",
    "    # number of rooms\n",
    "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
    "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
    "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
    "    \n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
    "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
    "    \n",
    "    # property type\n",
    "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
    "                                                  'ok':'single-family house'})\n",
    "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def geocode_address(df):\n",
    "    key = os.getenv('opencage_api')\n",
    "    geocoder = OpenCageGeocode(key)\n",
    "    postcode_dict = {}\n",
    "    district_geocode = df['district'].unique() # find list of unique postcode\n",
    "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
    "\n",
    "    for i in range(0, len(district_geocode)):\n",
    "        result= geocoder.geocode(district_geocode[i])\n",
    "        if len(result) > 1:            \n",
    "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
    "        else:       \n",
    "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
    "\n",
    "            \n",
    "    return postcode_dict    \n",
    "\n",
    "def merge_district(postcode_dict, df):\n",
    "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
    "    df_postcode.columns= ['district', 'postcode']\n",
    "    \n",
    "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
    "                                                         \n",
    "    df = df.merge(df_postcode, on='district')\n",
    "            \n",
    "    return  df\n",
    "\n",
    "def geocode_address(df):\n",
    "    key = os.getenv('OPENCAGE_API_KEY')\n",
    "    geocoder = OpenCageGeocode(key)\n",
    "\n",
    "    postcode_dict = {}\n",
    "    postcode_null = []\n",
    "    district_geocode = df['district'].unique() # find list of unique postcode\n",
    "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
    "\n",
    "    for i in range(0, len(district_geocode)):\n",
    "        result= geocoder.geocode(district_geocode[i])\n",
    "        if len(result) > 1:\n",
    "            try:\n",
    "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
    "            except :\n",
    "                print(district_geocode[i])\n",
    "                postcode_null.append(district_geocode[i])\n",
    "        else:       \n",
    "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
    "      \n",
    "    return postcode_dict, postcode_null    \n",
    "\n",
    "\n",
    "def merge_district(postcode_dict, df):  \n",
    "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
    "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
    "    df_postcode.columns= ['district', 'postcode']\n",
    "    \n",
    "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
    "                                                          \n",
    "    df= df.merge(df_postcode, on='district')\n",
    "    print('Geocode postcode for df transaction price: done')\n",
    "            \n",
    "    return  df\n",
    " \n",
    "def process_transaction_df():\n",
    "    df = clean_transaction_price()\n",
    "    postcode_geo, postcode_null = geocode_address(df) \n",
    "    df = merge_district(postcode_geo, df)\n",
    "    \n",
    "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
    "    print('==== Save df transaction price: done ====')\n",
    "       \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# clean asking price df\n",
    "# ============================================\n",
    "\n",
    "def clean_df_listing():\n",
    "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
    "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
    "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
    "\n",
    "    # clean municipality\n",
    "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
    "    # number_of_room\n",
    "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
    "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
    "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
    "\n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
    "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
    "    \n",
    "    # maitenance cost per sqm\n",
    "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
    "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
    "    \n",
    "    # filter potential wrong values\n",
    "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
    "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
    "                                                           # property sold with >20k/m2\n",
    "    # divide propery into 2 groups: house and apartment:\n",
    "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
    "    \n",
    "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
    "    print('==== Save df asking price: done ====')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================\n",
    "# clean rent df\n",
    "# ============================================\n",
    "\n",
    "def load_rent():\n",
    "    # load file\n",
    "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
    "    \n",
    "    # clean columns\n",
    "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
    "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
    "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
    "    \n",
    "    # change dtype of rent columns\n",
    "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # drop unneeded columns:\n",
    "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
    "\n",
    "    df.to_csv('../data/processed/rent.csv', index=False)\n",
    "    print('==== Save df rent: done ====')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# merge df_rent, df_price and df_listing\n",
    "# ============================================\n",
    "\n",
    "def caculate_yield(x):\n",
    "    if x['new']:\n",
    "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
    "    else:\n",
    "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
    "    \n",
    "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
    "    \n",
    "    return x['net_yield']\n",
    "\n",
    "def merge_df(df_rent, df_listing, df_price):\n",
    "    # correct format of postcode:\n",
    "    for df in [df_rent, df_listing, df_price]:\n",
    "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
    "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
    "        if 'number_of_room_cat' in df.columns:\n",
    "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
    "            \n",
    "    # merge price and listing\n",
    "\n",
    "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
    "                ['price_m2'].mean().reset_index()\n",
    "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
    "                ['asking_price_m2'].mean().reset_index()\n",
    "    \n",
    "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
    "                      how='left').drop_duplicates()\n",
    "    \n",
    "    # merge df listing and df rent\n",
    "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
    "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
    "   \n",
    "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
    "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
    "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
    "    \n",
    "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
    "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
    "   \n",
    "    print('==== Save df yield and price: done ====')\n",
    "    \n",
    "    \n",
    "    return df_listing_price, df_yield\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Start')\n",
    "    # df_rent = load_rent()\n",
    "    df_price = process_transaction_df()\n",
    "    # df_listing = clean_df_listing()\n",
    "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\user\\anaconda3\\python.exe' 'C:\\Users\\user\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\user\\AppData\\Local\\Temp\\tmpip36khlo'\n",
      "       cwd: C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-k9rjg6te\\pyproj\n",
      "  Complete output (1 lines):\n",
      "  proj executable not found. Please set the PROJ_DIR variable. For more information see: https://pyproj4.github.io/pyproj/stable/installation.html\n",
      "  ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\user\\anaconda3\\python.exe' 'C:\\Users\\user\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\user\\AppData\\Local\\Temp\\tmpip36khlo' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.0.1.tar.gz (168 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/1: runfile('C:/Users/user/.spyder-py3/temp.py', wdir='C:/Users/user/.spyder-py3')\n",
      " 2/2: runfile('C:/Users/user/.spyder-py3/temp.py', wdir='C:/Users/user/.spyder-py3')\n",
      " 2/3: runfile('C:/Users/user/.spyder-py3/temp.py', wdir='C:/Users/user/.spyder-py3')\n",
      " 2/4: addNumbers\n",
      " 2/5: addNumbers()\n",
      " 2/6: runfile('C:/Users/user/.spyder-py3/temp.py', wdir='C:/Users/user/.spyder-py3')\n",
      " 2/7: addNumbers()\n",
      " 2/8: 2 + 2\n",
      " 2/9: 2 + 2\n",
      " 3/1: 2+2\n",
      " 3/2: 2**3\n",
      " 3/3: 4**2\n",
      " 3/4: 22%8\n",
      " 3/5: 15%3\n",
      " 3/6: 22/8\n",
      " 3/7: 15/7\n",
      " 3/8: 15/2\n",
      " 3/9: 10//2\n",
      "3/10: 11/2\n",
      "3/11: 11//2\n",
      "3/12: 11/3\n",
      "3/13: 11//3\n",
      "3/14: 2*3\n",
      "3/15: 2**3\n",
      " 4/1:\n",
      "import pandas as pd #data handling and manipulation\n",
      "import numpy as np #values from data\n",
      "import matplotlib.pyplot as plt #plots\n",
      " 4/2:\n",
      "# get the data as pandas data frame\n",
      "df = pd.read_csv(\"./intro_to_jupyter.csv\", sep=';',encoding='utf8',low_memory=False)\n",
      "df = df.drop('Unnamed: 0', axis = 1)\n",
      " 4/3: df.head()\n",
      " 4/4:\n",
      "#check the unique values of the renovation life span in pipe renovations\n",
      "np.sort(df.pipeRenSpan.unique())\n",
      " 4/5:\n",
      "import pandas as pd #data handling and manipulation\n",
      "import numpy as np #values from data\n",
      "import matplotlib.pyplot as plt #plots\n",
      " 4/6:\n",
      "#create new data frames for maintenance and part change renovations\n",
      "df_maintenance = df[df.pipeRenovationType == 'maintenance']\n",
      "df_pc = df[df.pipeRenovationType == 'part change']\n",
      " 4/7:\n",
      "#create new data frames for maintenance and part change renovations\n",
      "df_maintenance = df[df.pipeRenovationType == 'maintenance']\n",
      "df_pc = df[df.pipeRenovationType == 'part change']\n",
      " 4/8:\n",
      "#create new data frames for maintenance and part change renovations\n",
      "df_maintenance = df[df.pipeRenovationType == 'maintenance']\n",
      "df_pc = df[df.pipeRenovationType == 'part change']\n",
      " 4/9:\n",
      "import pandas as pd #data handling and manipulation\n",
      "import numpy as np #values from data\n",
      "import matplotlib.pyplot as plt #plots\n",
      "4/10:\n",
      "# get the data as pandas data frame\n",
      "df = pd.read_csv(\"./intro_to_jupyter.csv\", sep=';',encoding='utf8',low_memory=False)\n",
      "df = df.drop('Unnamed: 0', axis = 1)\n",
      "4/11: df.head()\n",
      "4/12:\n",
      "#get the mean and standard deviation\n",
      "print np.mean(df.pipeRenSpan)\n",
      "print np.std(df.pipeRenSpan)\n",
      "4/13:\n",
      "#check the unique values of the renovation life span in pipe renovations\n",
      "np.sort(df.pipeRenSpan.unique())\n",
      " 5/1:\n",
      "import pandas as pd #data handling and manipulation\n",
      "import numpy as np #values from data\n",
      "import matplotlib.pyplot as plt #plots\n",
      " 5/2:\n",
      "# get the data as pandas data frame\n",
      "df = pd.read_csv(\"./intro_to_jupyter.csv\", sep=';',encoding='utf8',low_memory=False)\n",
      "df = df.drop('Unnamed: 0', axis = 1)\n",
      " 5/3: df.head()\n",
      " 5/4:\n",
      "#check the unique values of the renovation life span in pipe renovations\n",
      "np.sort(df.pipeRenSpan.unique())\n",
      " 5/5:\n",
      "#get the mean and standard deviation\n",
      "print np.mean(df.pipeRenSpan)\n",
      "print np.std(df.pipeRenSpan)\n",
      " 5/6:\n",
      "#create new data frames for maintenance and part change renovations\n",
      "df_maintenance = df[df.pipeRenovationType == 'maintenance']\n",
      "df_pc = df[df.pipeRenovationType == 'part change']\n",
      " 5/7:\n",
      "#create new data frames for maintenance and part change renovations\n",
      "df_maintenance = df[df.pipeRenovationType == 'maintenance']\n",
      "df_pc = df[df.pipeRenovationType == 'part change']\n",
      " 5/8:\n",
      "#create a data frame where we have grouped by pipe renovation life span and included frequency\n",
      "x_and_y = df.groupby(['pipeRenSpan']).size().reset_index(name='freq')\n",
      "x_and_y.head()\n",
      " 5/9:\n",
      "x_and_y = df_maintenance.groupby(['pipeRenSpan']).size().reset_index(name='freq')\n",
      "frequence = x_and_y.freq.tolist() \n",
      "value = x_and_y.pipeRenSpan.tolist()\n",
      "plt.plot(value, frequence)\n",
      "plt.ylabel('frequency')\n",
      "plt.show()\n",
      "5/10:\n",
      "for x in np.sort(df_pc.buildDecade.unique()):\n",
      "    df_decade = df_pc[df_pc.buildDecade == x]\n",
      "    if len(df_decade) > 30:\n",
      "        x_and_y = df_decade.groupby(['pipeRenSpan']).size().reset_index(name='freq')\n",
      "        frequence = x_and_y.freq.tolist() \n",
      "        value = x_and_y.pipeRenSpan.tolist()\n",
      "        plt.plot(value, frequence)\n",
      "        plt.ylabel('pipe renovations in buildings built in ' + str(x))\n",
      "        plt.xlabel('years from build year')\n",
      "        plt.show()\n",
      "        print 'The mean is ' + str(np.mean(df_decade.pipeRenSpan)) + ' and the std is ' + str(np.std(df_decade.pipeRenSpan))\n",
      "5/11:\n",
      "for x in np.sort(df_pc.buildDecade.unique()):\n",
      "    df_decade = df_pc[df_pc.buildDecade == x]\n",
      "    if len(df_decade) > 30:\n",
      "        x_and_y = df_decade.groupby(['pipeRenSpan']).size().reset_index(name='freq')\n",
      "        frequence = x_and_y.freq.tolist() \n",
      "        value = x_and_y.pipeRenSpan.tolist()\n",
      "        plt.plot(value, frequence)\n",
      "        plt.ylabel('pipe renovations in buildings built in ' + str(x))\n",
      "        plt.xlabel('years from build year')\n",
      "        plt.show()\n",
      "        print 'The mean is ' + str(np.mean(df_decade.pipeRenSpan)) + ' and the std is ' + str(np.std(df_decade.pipeRenSpan))\n",
      "5/12:\n",
      "for x in np.sort(df_pc.buildDecade.unique()):\n",
      "    df_decade = df_pc[df_pc.buildDecade == x]\n",
      "    if len(df_decade) > 30:\n",
      "        x_and_y = df_decade.groupby(['pipeRenSpan']).size().reset_index(name='freq')\n",
      "        frequence = x_and_y.freq.tolist() \n",
      "        value = x_and_y.pipeRenSpan.tolist()\n",
      "        plt.plot(value, frequence)\n",
      "        plt.ylabel('pipe renovations in buildings built in ' + str(x))\n",
      "        plt.xlabel('years from build year')\n",
      "        plt.show()\n",
      "        print 'The mean is ' + str(np.mean(df_decade.pipeRenSpan)) + ' and the std is ' + str(np.std(df_decade.pipeRenSpan))\n",
      " 6/1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sys\n",
      "import os\n",
      "import json\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "sys.path.append('../')\n",
      "from utils import *\n",
      "\n",
      "pd.set_option('display.max_columns',100)\n",
      " 6/2:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sys\n",
      "import os\n",
      "import json\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "sys.path.append('../')\n",
      "#from utils import *\n",
      "\n",
      "pd.set_option('display.max_columns',100)\n",
      " 9/1:\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "10/1:\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "10/2: df = pd.read_csv(\"../datasets/chap5_data/datasetschap5_data\")\n",
      "10/3:\n",
      "df = pd.read_csv(\"../datasets/chap5_data/AirPassengersDates.csv\")\n",
      "\n",
      "#datasetschap5_data\n",
      "10/4: df>head()\n",
      "10/5: df.head()\n",
      "10/6: df['Date'] = pd.to_datetimes(df['Date'])\n",
      "10/7: df['Date'] = pd.to_datetime(df['Date'])\n",
      "10/8: df.head()\n",
      "10/9:\n",
      "df['year'] = df['Date'].dt.year\n",
      "df['month'] = df['Date'].dt.month\n",
      "df['day'] = df['Date'].dt.yday\n",
      "df['day_name'] = df['Date'].dt.day_name\n",
      "10/10:\n",
      "df['year'] = df['Date'].dt.year\n",
      "df['month'] = df['Date'].dt.month\n",
      "df['day'] = df['Date'].dt.day\n",
      "df['day_name'] = df['Date'].dt.day_name\n",
      "10/11: df.head()\n",
      "10/12:\n",
      "df['year'] = df['Date'].dt.year\n",
      "df['month'] = df['Date'].dt.month\n",
      "df['day'] = df['Date'].dt.day\n",
      "df['day_name'] = df['Date'].dt.day_name()\n",
      "10/13: df.head()\n",
      "10/14:\n",
      "# analyse based on month\n",
      "df_month = df.groupby('month').sum().reset_index()\n",
      "10/15: impor seaborn as sns\n",
      "10/16: import seaborn as sns\n",
      "10/17:\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "10/18:\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "10/19:\n",
      "# analyse based on month\n",
      "df_month = df.groupby('month').sum().reset_index()\n",
      "df_month.head()\n",
      "10/20:\n",
      "# analyse based on month\n",
      "df_month = df.groupby('month')['#Passengers'].sum().reset_index()\n",
      "df_month.head()\n",
      "10/21: sns.barplot('#Passengers', df_month)\n",
      "10/22: sns.barplot(x='#Passengers', df_month)\n",
      "10/23: sns.barplot(x='#Passengers', data=df_month)\n",
      "10/24: sns.barplot(x='month', y='#Passengers', data=df_month)\n",
      "10/25:\n",
      "import plotly.express as px\n",
      "px.bar((x='month', y='#Passengers', data=df_month)\n",
      "10/26:\n",
      "import plotly.express as px\n",
      "px.bar(x='month', y='#Passengers', data=df_month)\n",
      "10/27:\n",
      "import plotly.express as px\n",
      "px.bar(x='month', y='#Passengers',df_month)\n",
      "10/28:\n",
      "import plotly.express as px\n",
      "px.bar(x='month', y='#Passengers',data_frame=df_month)\n",
      "10/29:\n",
      "import plotly.express as px\n",
      "px.bar(x='month', y='#Passengers',data_frame=df_month,\n",
      "       title='Number of passessgers according to month'\n",
      ")\n",
      "10/30: ax +sns.barplot(x='month', y='#Passengers', data=df_month)\n",
      "10/31: ax = sns.barplot(x='month', y='#Passengers', data=df_month)\n",
      "10/32: ax.patches\n",
      "10/33: len(ax.patches)\n",
      "10/34: ax.patches\n",
      "10/35: ax.patches[0]\n",
      "10/36: ax.patches[0].get_high()\n",
      "10/37: ax.patches[0].get_heigh()\n",
      "10/38: ax.patches[0].get_height()\n",
      "10/39:\n",
      "ax.set_title(\"Bar Plot - Passengers per month\")\n",
      "\n",
      "#Annotate the bars with value to have better idea\n",
      "\n",
      "for p, v in zip(ax.patches, passenger_per_month['#Passengers']):\n",
      "\n",
      "    height = p.get_height()\n",
      "\n",
      "    ax.text(p.get_x() + p.get_width() / 2, height + 5, v,\n",
      "\n",
      "            ha='center', va='bottom')\n",
      "10/40:\n",
      "ax.set_title(\"Bar Plot - Passengers per month\")\n",
      "\n",
      "#Annotate the bars with value to have better idea\n",
      "\n",
      "for p, v in zip(ax.patches, df_month['#Passengers']):\n",
      "\n",
      "    height = p.get_height()\n",
      "\n",
      "    ax.text(p.get_x() + p.get_width() / 2, height + 5, v,\n",
      "\n",
      "            ha='center', va='bottom')\n",
      "10/41:\n",
      "ax.set_title(\"Bar Plot - Passengers per month\")\n",
      "\n",
      "#Annotate the bars with value to have better idea\n",
      "\n",
      "for p, v in zip(ax.patches, df_month['#Passengers']):\n",
      "\n",
      "    height = p.get_height()\n",
      "\n",
      "    ax.text(p.get_x() + p.get_width() / 2, height + 5, v,\n",
      "\n",
      "            ha='center', va='bottom')\n",
      "10/42:\n",
      "import plotly.express as px\n",
      "px.bar(x='month', y='#Passengers',data_frame=df_month,\n",
      "       title='Number of passessgers according to month'\n",
      ")\n",
      "10/43:\n",
      "ax.set_title(\"Bar Plot - Passengers per month\")\n",
      "\n",
      "#Annotate the bars with value to have better idea\n",
      "\n",
      "for p, v in zip(ax.patches, df_month['#Passengers']):\n",
      "\n",
      "    height = p.get_height()\n",
      "\n",
      "    ax.text(p.get_x() + p.get_width() / 2, height + 5, v,\n",
      "\n",
      "            ha='center', va='bottom')\n",
      "    \n",
      "plt.show()\n",
      "11/1:\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "11/2: df = pd.read_csv(\"../datasets/chap5_data/AirPassengersDates.csv\")\n",
      "11/3: df.head()\n",
      "11/4: df['Date'] = pd.to_datetime(df['Date'])\n",
      "11/5:\n",
      "df['year'] = df['Date'].dt.year\n",
      "df['month'] = df['Date'].dt.month\n",
      "df['day'] = df['Date'].dt.day\n",
      "df['day_name'] = df['Date'].dt.day_name()\n",
      "11/6:\n",
      "# analyse based on month\n",
      "df_month = df.groupby('month')['#Passengers'].sum().reset_index()\n",
      "df_month.head()\n",
      "11/7:\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "11/8: ax = sns.barplot(x='month', y='#Passengers', data=df_month)\n",
      "11/9:\n",
      "ax.set_title(\"Bar Plot - Passengers per month\")\n",
      "\n",
      "#Annotate the bars with value to have better idea\n",
      "\n",
      "for p, v in zip(ax.patches, df_month['#Passengers']):\n",
      "\n",
      "    height = p.get_height()\n",
      "\n",
      "    ax.text(p.get_x() + p.get_width() / 2, height + 5, v,\n",
      "\n",
      "            ha='center', va='bottom')\n",
      "    \n",
      "plt.show()\n",
      "11/10:\n",
      "import plotly.express as px\n",
      "px.bar(x='month', y='#Passengers',data_frame=df_month,\n",
      "       title='Number of passessgers according to month'\n",
      ")\n",
      "11/11:\n",
      "# line plot with ci\n",
      "ax = sns.lineplot(x=\"month\",y=\"#Passengers\", data=df, ci=80)\n",
      "11/12:\n",
      "# caculate zscore\n",
      "df['zscore'] = (df['#Passengers'] - df['#Passengers'].mean()) / df['#Passengers'].std()\n",
      "11/13: df['zscore'\n",
      "11/14: df['zscore']\n",
      "11/15: df.sort_values(by='zscore')\n",
      "11/16: df = df.sort_values(by='zscore')\n",
      "11/17: df\n",
      "11/18:\n",
      "# caculate zscore\n",
      "df['zscore'] = (df['#Passengers'] - df['#Passengers'].mean()) / df['#Passengers'].std()\n",
      "df['zscore'] = np.abs(df['zscore'])\n",
      "11/19: df\n",
      "11/20:\n",
      "df = df.sort_values(by='zscore')\n",
      "df_low = df.head(10)\n",
      "df_high = df.tail(10)\n",
      "11/21: df_low\n",
      "11/22: df_low.info()\n",
      "11/23: sns.lineplot(x='Date', y = '#Passengers', df)\n",
      "11/24: sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "11/25:\n",
      "plt.figure(figure_size = (15, 8))\n",
      "sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "11/26:\n",
      "plt.figure(figsize = (15, 8))\n",
      "sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "11/27:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatter(x='Date', y = '#Passengers', data=df_low)\n",
      "11/28:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low)\n",
      "11/29:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_high)\n",
      "11/30: df\n",
      "11/31: df.tai(10)\n",
      "11/32: df.tail(10)\n",
      "11/33: df.head(10)\n",
      "11/34:\n",
      "df = df.sort_values(by='zscore')\n",
      "df_low = df.head(10)\n",
      "df_high = df.tail(10)\n",
      "11/35:\n",
      "# caculate zscore\n",
      "df['zscore'] = (df['#Passengers'] - df['#Passengers'].mean()) / df['#Passengers'].std()\n",
      "#df['zscore'] = np.abs(df['zscore'])\n",
      "11/36:\n",
      "df = df.sort_values(by='zscore')\n",
      "df_low = df.head(10)\n",
      "df_high = df.tail(10)\n",
      "11/37: df.head(10)\n",
      "11/38:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low)\n",
      "11/39:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers')\n",
      "11/40:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers' , color='orange')\n",
      "11/41:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers' , color='orange')\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_high, size='#Passengers' , color='green')\n",
      "11/42:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers' , color='orange')\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_high, size='#Passengers' , color='green')\n",
      "ax = sns.lineplot(y=np.mean(df['#Passengers']), x= 'Date', data=df)\n",
      "11/43:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers' , color='orange')\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_high, size='#Passengers' , color='green')\n",
      "ax = sns.lineplot( x= 'Date' , y=np.mean(df['#Passengers']), data=df)\n",
      "11/44:\n",
      "df = df.sort_values(by='zscore')\n",
      "df_low = df.head(10)\n",
      "df_high = df.tail(10)\n",
      "df['mean'] = df['#Passengers'].mean()\n",
      "11/45:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers' , color='orange')\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_high, size='#Passengers' , color='green')\n",
      "ax = sns.lineplot( x= 'Date' , y='mean'), data=df)\n",
      "11/46:\n",
      "plt.figure(figsize = (15, 8))\n",
      "ax = sns.lineplot(x='Date', y = '#Passengers', data=df)\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_low, size='#Passengers' , color='orange')\n",
      "ax = sns.scatterplot(x='Date', y = '#Passengers', data=df_high, size='#Passengers' , color='green')\n",
      "ax = sns.lineplot( x= 'Date' , y='mean', data=df)\n",
      "11/47:\n",
      "### upsampling and downsampling\n",
      "\n",
      "df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "11/48: df.samle(6)\n",
      "11/49: df.sample(6)\n",
      "11/50: sns.heatmap(df.isnull())\n",
      "11/51:\n",
      "df_count = df.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\")\\\n",
      "\n",
      ".rename(columns={\"storenum\": \"store_count\"})\n",
      "11/52:\n",
      "df_count = df.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\")\\\n",
      ".rename(columns={\"storenum\": \"store_count\"})\n",
      "11/53: df_count\n",
      "11/54:\n",
      "df_count = df.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\")\\\n",
      ".rename(columns={\"storenum\": \"store_count\"})\n",
      "\n",
      "df_count = pd.merge(df, df_count, on=\"YEAR\")\n",
      "11/55: df_count\n",
      "11/56:\n",
      "#set index\n",
      "df_count.index = df['date_super']\n",
      "11/57: df_count\n",
      "11/58: df_count.info()\n",
      "11/59:\n",
      "#set index\n",
      "df['date_super']= pd.datetime(df['date_super'])\n",
      "df_count.index = df['date_super']\n",
      "11/60:\n",
      "#set index\n",
      "df['date_super']= pd.to_datetime(df['date_super'])\n",
      "df_count.index = df['date_super']\n",
      "11/61: df_count.info()\n",
      "11/62: df_count\n",
      "11/63:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count.drop_duplicates(subset=\"date_super\", inplace=True)\n",
      "11/64: df_count\n",
      "11/65:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates()\n",
      "11/66: df_count\n",
      "11/67: df_count.head(10)\n",
      "11/68:\n",
      "walmart_store_count_series = df_count.store_count\n",
      "\n",
      "walmart_store_count_series = walmart_store_count_series.asfreq('2D')\n",
      "\n",
      "walmart_store_count_series.head()\n",
      "11/69: df_count.store_count\n",
      "11/70: df_count.store_count.asfreq('2D')\n",
      "11/71: df_count.store_count\n",
      "12/1:\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "12/2: df = pd.read_csv(\"../datasets/chap5_data/AirPassengersDates.csv\")\n",
      "13/1:\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "13/2:\n",
      "df = pd.read_csv(\"../datasets/chap5_data/AirPassengersDates.csv\")\n",
      "df = df.dropna(subset=['date_super'])\n",
      "13/3: df = pd.read_csv(\"../datasets/chap5_data/AirPassengersDates.csv\")\n",
      "13/4: df.head()\n",
      "13/5:\n",
      "### upsampling and downsampling\n",
      "\n",
      "df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "13/6: df.head()\n",
      "13/7:\n",
      "### upsampling and downsampling\n",
      "\n",
      "df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "df.dropna(subset=['date_super'])\n",
      "13/8:\n",
      "### upsampling and downsampling\n",
      "\n",
      "df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "df=df.dropna(subset=['date_super'])\n",
      "13/9: df.head()\n",
      "13/10:\n",
      "df_count = df.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\")\\\n",
      ".rename(columns={\"storenum\": \"store_count\"})\n",
      "\n",
      "df_count = pd.merge(df, df_count, on=\"YEAR\")\n",
      "13/11:\n",
      "#set index\n",
      "df['date_super']= pd.to_datetime(df['date_super'])\n",
      "df_count.index = df['date_super']\n",
      "13/12:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates()\n",
      "13/13: df_count.head(10)\n",
      "13/14:\n",
      "store_count_series = df_count.store_count\n",
      "store_count_series = store_count_series.asfreq('2D')\n",
      "13/15:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series = store_count_series.asfreq('2D')\n",
      "13/16:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/17:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/18:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/19:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates()\n",
      "13/20: df_count.head(10)\n",
      "13/21:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/22:\n",
      "### upsampling and downsampling\n",
      "\n",
      "df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "df=df.dropna(subset=['date_super'])\n",
      "13/23: df.head()\n",
      "13/24:\n",
      "df_count = df.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\")\\\n",
      ".rename(columns={\"storenum\": \"store_count\"})\n",
      "\n",
      "df_count = pd.merge(df, df_count, on=\"YEAR\")\n",
      "13/25:\n",
      "#set index\n",
      "df['date_super']= pd.to_datetime(df['date_super'])\n",
      "df_count.index = df['date_super']\n",
      "13/26:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates()\n",
      "13/27: df_count.head(10)\n",
      "13/28:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/29:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates()\n",
      "13/30:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/31:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates(subset=\"date_super\")\n",
      "13/32:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/33:\n",
      "df_count = df.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\")\\\n",
      ".rename(columns={\"storenum\": \"store_count\"})\n",
      "\n",
      "df_count = pd.merge(df, df_count, on=\"YEAR\")\n",
      "13/34:\n",
      "#set index\n",
      "df['date_super']= pd.to_datetime(df['date_super'])\n",
      "df_count.index = df['date_super']\n",
      "13/35: df_count\n",
      "13/36:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates(subset=\"date_super\")\n",
      "13/37:\n",
      "store_count_series = df_count['store_count']\n",
      "store_count_series.asfreq('2D')\n",
      "#store_count_series = store_count_series.asfreq('2D')\n",
      "13/38:\n",
      "store_count_series = df_count['store_count']\n",
      "#store_count_series.asfreq('2D')\n",
      "store_count_series = store_count_series.asfreq('2D')\n",
      "13/39: df_count.head(5)\n",
      "13/40: store_count_series\n",
      "13/41: store_count_series.interpolate('spline')\n",
      "13/42: store_count_series.interpolate(method='spline')\n",
      "13/43: store_count_series.interpolate(method='spline', order=2)\n",
      "13/44: store_count_series.interpolate(method='spline', order=3)\n",
      "13/45: store_count_series.interpolate(method='spline', order=2)\n",
      "13/46: store_count_series = store_count_series.interpolate(method='spline', order=2)\n",
      "13/47: store_count_series.plot(kind=':')\n",
      "13/48: store_count_series.plot(style=':')\n",
      "13/49:\n",
      "store_count_series = df_count['store_count']\n",
      "#store_count_series.asfreq('2D')\n",
      "store_count_series = store_count_series.asfreq('2D')\n",
      "13/50: store_count_series1 = store_count_series.interpolate(method='spline', order=2)\n",
      "13/51: store_count_series.plot(style=':')\n",
      "13/52: store_count_series1.plot(style=':')\n",
      "13/53:\n",
      "store_count_series2 = store_count_series.interpolate(method='linear')\n",
      "store_count_series2.plot(style=':')\n",
      "13/54:\n",
      "store_count_series1 = store_count_series.interpolate(method='spline', order=3)\n",
      "store_count_series1.plot(style=':')\n",
      "13/55:\n",
      "df_count = df_count[[\"date_super\", \"store_count\"]]\n",
      "df_count = df_count.drop_duplicates(subset=\"date_super\")\n",
      "13/56:\n",
      "store_count_series = df_count['store_count']\n",
      "#store_count_series.asfreq('2D')\n",
      "store_count_series = store_count_series.asfreq('2D')\n",
      "13/57: store_count_series1 = store_count_series.interpolate(method='spline', order=2)\n",
      "13/58: store_count_series1.plot(style=':')\n",
      "13/59:\n",
      "plt.figure(figsize=(12,8))\n",
      "\n",
      "plt.ylabel(\"Interpolated Values\")\n",
      "\n",
      "plt.plot(walmart_store_count_series)\n",
      "13/60:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "13/61:\n",
      "plt.figure(figsize=(12,8))\n",
      "\n",
      "plt.ylabel(\"Interpolated Values\")\n",
      "\n",
      "plt.plot(walmart_store_count_series)\n",
      "13/62:\n",
      "plt.figure(figsize=(12,8))\n",
      "\n",
      "plt.ylabel(\"Interpolated Values\")\n",
      "\n",
      "plt.plot(store_count_series1)\n",
      "13/63:\n",
      "plt.figure(figsize=(12,8))\n",
      "\n",
      "plt.ylabel(\"Interpolated Values\")\n",
      "\n",
      "plt.plot(store_count_series1)\n",
      "store_count_series1.resample('BA').mean().plot(style=':',\\\n",
      "                            title=\"Values Smoothen by Business Year Frequency\") #BA stands for Business Year\n",
      "13/64: store_count_series1.resample('BA')\n",
      "13/65: store_count_series1.resample('BA').mean()\n",
      "13/66: store_count_series1.resample('BQ').mean()\n",
      "13/67:\n",
      "plt.figure(figsize=(12,8))\n",
      "\n",
      "plt.ylabel(\"Interpolated Values\")\n",
      "\n",
      "plt.plot(store_count_series1)\n",
      "store_count_series1.resample('BQ').mean().plot(style=':',\\\n",
      "                            title=\"Values Smoothen by Business Year Frequency\") #BA stands for Business Year\n",
      "13/68:\n",
      "# tshift and shift\n",
      "# df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "walmart_stores = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\",\n",
      "\n",
      "parse_dates=['date_super']).dropna()\n",
      "\n",
      "walmart_store_count = walmart_stores.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\").rename(columns={\"storenum\": \"store_count\"})\n",
      "\n",
      "walmart_store_count = pd.merge(walmart_stores, walmart_store_count, on=\"YEAR\")\n",
      "\n",
      "walmart_store_count= walmart_store_count.set_index(pd.DatetimeIndex(walmart_store_count.date_super))\n",
      "\n",
      "walmart_store_count = walmart_store_count[[\"date_super\", \"store_count\"]]\n",
      "\n",
      "walmart_store_count.drop_duplicates(subset=\"date_super\", inplace=True)\n",
      "\n",
      "walmart_store_count_series = walmart_store_count.store_count\n",
      "\n",
      "walmart_store_count_series = walmart_store_count_series.asfreq('2D')\n",
      "\n",
      "walmart_store_count_series = walmart_store_count_series.interpolate(method=\"spline\", order=2)\n",
      "\n",
      "Create three plots: one normal, one shifted with index, and one shifted with time:\n",
      "walmart_store_count_series = walmart_store_count_series.asfreq('D', method='pad')\n",
      "\n",
      "Set up the plot and shift_val. shift_val is the value of the lag we want to plot on graphax[0].legend(['input'], loc=2):\n",
      "fig, ax = plt.subplots(3, figsize=(14,9))\n",
      "\n",
      "shift_val = 400\n",
      "\n",
      "#create 3 plots, one normal, one shifted with index, and other shifted with time\n",
      "\n",
      "walmart_store_count_series.plot(ax=ax[0])\n",
      "\n",
      "#shift the date by shift_val\n",
      "\n",
      "walmart_store_count_series.shift(shift_val).plot(ax=ax[1])\n",
      "\n",
      "#shift the time index using tshift\n",
      "\n",
      "walmart_store_count_series.tshift(shift_val).plot(ax=ax[2])\n",
      "\n",
      "#select a date to draw line on plot\n",
      "\n",
      "date_max = pd.to_datetime('2002-01-01')\n",
      "\n",
      "delta = pd.Timedelta(shift_val, 'D')\n",
      "\n",
      "#Put marker on three plot to undestand how thsift shifting the index and shift is changing the data.\n",
      "13/69:\n",
      "# tshift and shift\n",
      "# df = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\")\n",
      "walmart_stores = pd.read_csv(\"../datasets/chap5_data/1962_2006_walmart_store_openings.csv\",\n",
      "\n",
      "parse_dates=['date_super']).dropna()\n",
      "\n",
      "walmart_store_count = walmart_stores.groupby(\"YEAR\")[[\"storenum\"]].agg(\"count\").rename(columns={\"storenum\": \"store_count\"})\n",
      "\n",
      "walmart_store_count = pd.merge(walmart_stores, walmart_store_count, on=\"YEAR\")\n",
      "\n",
      "walmart_store_count= walmart_store_count.set_index(pd.DatetimeIndex(walmart_store_count.date_super))\n",
      "\n",
      "walmart_store_count = walmart_store_count[[\"date_super\", \"store_count\"]]\n",
      "\n",
      "walmart_store_count.drop_duplicates(subset=\"date_super\", inplace=True)\n",
      "\n",
      "walmart_store_count_series = walmart_store_count.store_count\n",
      "\n",
      "walmart_store_count_series = walmart_store_count_series.asfreq('2D')\n",
      "\n",
      "walmart_store_count_series = walmart_store_count_series.interpolate(method=\"spline\", order=2)\n",
      "13/70:\n",
      "# Create three plots: one normal, one shifted with index, and one shifted with time:\n",
      "walmart_store_count_series = walmart_store_count_series.asfreq('D', method='pad')\n",
      "walmart_store_count_series\n",
      "\n",
      "# Set up the plot and shift_val. shift_val is the value of the lag we want to plot on graphax[0].legend(['input'], loc=2):\n",
      "# fig, ax = plt.subplots(3, figsize=(14,9))\n",
      "# \n",
      "# shift_val = 400\n",
      "#\n",
      "13/71: walmart_store_count_series.shift\n",
      "13/72: walmart_store_count_series.tshift\n",
      "14/1: import np\n",
      "15/1: import np\n",
      "15/2: import numpy as np\n",
      "15/3:\n",
      "s1 = 'post'\n",
      "s2 = 'stop'\n",
      "15/4:\n",
      "l1 = s1.split()\n",
      "l2 = s2.split()\n",
      "\n",
      "set(l1, l2)\n",
      "15/5:\n",
      "l1 = s1.split()\n",
      "l2 = s2.split()\n",
      "\n",
      "set(l1) - set(l2)\n",
      "15/6: l1\n",
      "15/7:\n",
      "l1 = s1.split(sep='')\n",
      "l2 = s2.split()\n",
      "\n",
      "set(l1) - set(l2)\n",
      "15/8: list(s1)\n",
      "15/9:\n",
      "l1 = list(s1)\n",
      "l2 = list(s2)\n",
      "\n",
      "set(l1) - set(l2)\n",
      "15/10:\n",
      "def is_anagram(s1, s2):\n",
      "    l1 = list(s1)\n",
      "    l2 = list(s2)\n",
      "\n",
      "    if set(l1) - set(l2):\n",
      "        return True\n",
      "    else \n",
      "        False\n",
      "        \n",
      "is_anagram('stop', 'post')\n",
      "15/11:\n",
      "def is_anagram(s1, s2):\n",
      "    l1 = list(s1)\n",
      "    l2 = list(s2)\n",
      "\n",
      "    if set(l1) - set(l2):\n",
      "        return True\n",
      "    else :\n",
      "        False\n",
      "        \n",
      "is_anagram('stop', 'post')\n",
      "15/12:\n",
      "def is_anagram(s1, s2):\n",
      "    l1 = list(s1)\n",
      "    l2 = list(s2)\n",
      "\n",
      "    if set(l1) - set(l2) !=0:\n",
      "        return True\n",
      "    else :\n",
      "        False\n",
      "        \n",
      "is_anagram('stop', 'post')\n",
      "15/13:\n",
      "def is_anagram(s1, s2):\n",
      "    l1 = list(s1)\n",
      "    l2 = list(s2)\n",
      "\n",
      "    if set(l1) - set(l2) !=0:\n",
      "        return True\n",
      "    else :\n",
      "        False\n",
      "        \n",
      "is_anagram('stop', 'stopp')\n",
      "15/14:\n",
      "def is_anagram(s1, s2):\n",
      "    l1 = list(s1)\n",
      "    l2 = list(s2)\n",
      "\n",
      "    if np.setdiff(l1,l2) !=0:\n",
      "        return True\n",
      "    else :\n",
      "        False\n",
      "        \n",
      "is_anagram('stop', 'stopp')\n",
      "15/15:\n",
      "def is_anagram(s1, s2):\n",
      "    l1 = list(s1)\n",
      "    l2 = list(s2)\n",
      "\n",
      "    if np.setdiff1d(l1,l2) !=0:\n",
      "        return True\n",
      "    else :\n",
      "        False\n",
      "        \n",
      "is_anagram('stop', 'stopp')\n",
      "15/16:\n",
      "s1= 'stop'\n",
      "\n",
      "s1.sort()\n",
      "16/1:\n",
      "\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "16/2: ! pip install requests\n",
      "16/3:\n",
      "\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "16/4:\n",
      "\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "16/5:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "16/6: ! pip list\n",
      "17/1:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "17/2: ! pip uninstall requests\n",
      "19/1:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "19/2: ! pip install requests\n",
      "20/1:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "20/2:\n",
      "import pandas as pd\n",
      "pd.read_csv('asunto_sec.csv')\n",
      "20/3:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "import sys\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "    print(content)\n",
      "    sys.exit()\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "20/4:\n",
      "import requests\n",
      "import lxml.html as lh\n",
      "import pandas as pd\n",
      "21/1:\n",
      "#import scrapy\n",
      "\n",
      "class QuotesSpider(scrapy.Spider):\n",
      "    name = \"price\"\n",
      "    def self(\n",
      "\n",
      "    start_urls = [\n",
      "        f\"https://asuntojen.hintatiedot.fi/haku/?c=Vantaa&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "    ]\n",
      "    def __init__(self, url):\n",
      "        self.url = url\n",
      "        self.response = requests.get(url) # Send GET request and receive response\n",
      "        #self.content = response.text \n",
      "#         self.company = company\n",
      "#         self.speed_limit = speed_limit\n",
      "#         self.model = model \n",
      "\n",
      "    def parse(self, response):       \n",
      "        for url in start_urls:\n",
      "            next_page = response.css('#next-prev-top').get() \n",
      "            if re.search(next_page, \"seuraava sivu\"): # if page contains next page, then yield request\n",
      "                yield scrapy.Request(url, callback=self.parse_book)\n",
      "\n",
      "    def parse(self, response):\n",
      "        rows =  response.xpath('//*[@id=\"mainTable\"]/tbody[3]')\n",
      "        for row in rows.css('tr'):         \n",
      "            yield {\n",
      "                'district' : row.xpath('td[1]/text()').get(),\n",
      "                'apartment_type' : row.xpath('td[2]/text()').get(),\n",
      "                'property_type' : row.xpath('td[3]/text()').get(),\n",
      "                'floor_area' : row.xpath('td[4]/text()').get(),\n",
      "                'price' : row.xpath('td[5]/text()').get(),                \n",
      "                'price_m2' : row.xpath('td[6]/text()').get(),\n",
      "                'build_year' : row.xpath('td[7]/text()').get(),\n",
      "                'floor' : row.xpath('td[8]/text()').get(),\n",
      "                'elevator' : row.xpath('td[9]/text()').get(),\n",
      "                'condition' : row.xpath('td[10]/text()').get(),\n",
      "                'plot' : row.xpath('td[11]/text()').get(),\n",
      "                'energy_class': row.xpath('td[12]/text()').get(),\n",
      "                'date_scrape': '2021-02'\n",
      "            }\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    process = CrawlerProcess({\n",
      "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
      "    })\n",
      "\n",
      "    process.crawl(QuotesSpider)\n",
      "    process.start() # the script will block here until the crawling is finished\n",
      "21/2:\n",
      "#import scrapy\n",
      "\n",
      "class QuotesSpider(scrapy.Spider):\n",
      "    name = \"price\"\n",
      "  \n",
      "\n",
      "    start_urls = [\n",
      "        f\"https://asuntojen.hintatiedot.fi/haku/?c=Vantaa&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "    ]\n",
      "    def __init__(self, url):\n",
      "        self.url = url\n",
      "        self.response = requests.get(url) # Send GET request and receive response\n",
      "        #self.content = response.text \n",
      "#         self.company = company\n",
      "#         self.speed_limit = speed_limit\n",
      "#         self.model = model \n",
      "\n",
      "    def parse(self, response):       \n",
      "        for url in start_urls:\n",
      "            next_page = response.css('#next-prev-top').get() \n",
      "            if re.search(next_page, \"seuraava sivu\"): # if page contains next page, then yield request\n",
      "                yield scrapy.Request(url, callback=self.parse_book)\n",
      "\n",
      "    def parse(self, response):\n",
      "        rows =  response.xpath('//*[@id=\"mainTable\"]/tbody[3]')\n",
      "        for row in rows.css('tr'):         \n",
      "            yield {\n",
      "                'district' : row.xpath('td[1]/text()').get(),\n",
      "                'apartment_type' : row.xpath('td[2]/text()').get(),\n",
      "                'property_type' : row.xpath('td[3]/text()').get(),\n",
      "                'floor_area' : row.xpath('td[4]/text()').get(),\n",
      "                'price' : row.xpath('td[5]/text()').get(),                \n",
      "                'price_m2' : row.xpath('td[6]/text()').get(),\n",
      "                'build_year' : row.xpath('td[7]/text()').get(),\n",
      "                'floor' : row.xpath('td[8]/text()').get(),\n",
      "                'elevator' : row.xpath('td[9]/text()').get(),\n",
      "                'condition' : row.xpath('td[10]/text()').get(),\n",
      "                'plot' : row.xpath('td[11]/text()').get(),\n",
      "                'energy_class': row.xpath('td[12]/text()').get(),\n",
      "                'date_scrape': '2021-02'\n",
      "            }\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    process = CrawlerProcess({\n",
      "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
      "    })\n",
      "\n",
      "    process.crawl(QuotesSpider)\n",
      "    process.start() # the script will block here until the crawling is finished\n",
      "21/3:\n",
      "import scrapy\n",
      "\n",
      "class QuotesSpider(scrapy.Spider):\n",
      "    name = \"price\"\n",
      "  \n",
      "\n",
      "    start_urls = [\n",
      "        f\"https://asuntojen.hintatiedot.fi/haku/?c=Vantaa&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "    ]\n",
      "    def __init__(self, url):\n",
      "        self.url = url\n",
      "        self.response = requests.get(url) # Send GET request and receive response\n",
      "        #self.content = response.text \n",
      "#         self.company = company\n",
      "#         self.speed_limit = speed_limit\n",
      "#         self.model = model \n",
      "\n",
      "    def parse(self, response):       \n",
      "        for url in start_urls:\n",
      "            next_page = response.css('#next-prev-top').get() \n",
      "            if re.search(next_page, \"seuraava sivu\"): # if page contains next page, then yield request\n",
      "                yield scrapy.Request(url, callback=self.parse_book)\n",
      "\n",
      "    def parse(self, response):\n",
      "        rows =  response.xpath('//*[@id=\"mainTable\"]/tbody[3]')\n",
      "        for row in rows.css('tr'):         \n",
      "            yield {\n",
      "                'district' : row.xpath('td[1]/text()').get(),\n",
      "                'apartment_type' : row.xpath('td[2]/text()').get(),\n",
      "                'property_type' : row.xpath('td[3]/text()').get(),\n",
      "                'floor_area' : row.xpath('td[4]/text()').get(),\n",
      "                'price' : row.xpath('td[5]/text()').get(),                \n",
      "                'price_m2' : row.xpath('td[6]/text()').get(),\n",
      "                'build_year' : row.xpath('td[7]/text()').get(),\n",
      "                'floor' : row.xpath('td[8]/text()').get(),\n",
      "                'elevator' : row.xpath('td[9]/text()').get(),\n",
      "                'condition' : row.xpath('td[10]/text()').get(),\n",
      "                'plot' : row.xpath('td[11]/text()').get(),\n",
      "                'energy_class': row.xpath('td[12]/text()').get(),\n",
      "                'date_scrape': '2021-02'\n",
      "            }\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    process = CrawlerProcess({\n",
      "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
      "    })\n",
      "\n",
      "    process.crawl(QuotesSpider)\n",
      "    process.start() # the script will block here until the crawling is finished\n",
      "21/4: ! pip install scrapy\n",
      "21/5:\n",
      "import scrapy\n",
      "\n",
      "class QuotesSpider(scrapy.Spider):\n",
      "    name = \"price\"\n",
      "  \n",
      "\n",
      "    start_urls = [\n",
      "        f\"https://asuntojen.hintatiedot.fi/haku/?c=Vantaa&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "    ]\n",
      "\n",
      "    def parse(self, response):       \n",
      "        for url in start_urls:\n",
      "            next_page = response.css('#next-prev-top').get() \n",
      "            if re.search(next_page, \"seuraava sivu\"): # if page contains next page, then yield request\n",
      "                yield scrapy.Request(url, callback=self.parse_book)\n",
      "\n",
      "    def parse(self, response):\n",
      "        rows =  response.xpath('//*[@id=\"mainTable\"]/tbody[3]')\n",
      "        for row in rows.css('tr'):         \n",
      "            yield {\n",
      "                'district' : row.xpath('td[1]/text()').get(),\n",
      "                'apartment_type' : row.xpath('td[2]/text()').get(),\n",
      "                'property_type' : row.xpath('td[3]/text()').get(),\n",
      "                'floor_area' : row.xpath('td[4]/text()').get(),\n",
      "                'price' : row.xpath('td[5]/text()').get(),                \n",
      "                'price_m2' : row.xpath('td[6]/text()').get(),\n",
      "                'build_year' : row.xpath('td[7]/text()').get(),\n",
      "                'floor' : row.xpath('td[8]/text()').get(),\n",
      "                'elevator' : row.xpath('td[9]/text()').get(),\n",
      "                'condition' : row.xpath('td[10]/text()').get(),\n",
      "                'plot' : row.xpath('td[11]/text()').get(),\n",
      "                'energy_class': row.xpath('td[12]/text()').get(),\n",
      "                'date_scrape': '2021-02'\n",
      "            }\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    process = CrawlerProcess({\n",
      "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
      "    })\n",
      "\n",
      "    process.crawl(QuotesSpider)\n",
      "    process.start() # the script will block here until the crawling is finished\n",
      "21/6:\n",
      "import scrapy\n",
      "\n",
      "class QuotesSpider(scrapy.Spider):\n",
      "    name = \"price\"\n",
      "  \n",
      "\n",
      "    start_urls = [\n",
      "        f\"https://asuntojen.hintatiedot.fi/haku/?c=Vantaa&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "    ]\n",
      "\n",
      "    def parse(self, response):       \n",
      "        for url in start_urls:\n",
      "            next_page = response.css('#next-prev-top').get() \n",
      "            if re.search(next_page, \"seuraava sivu\"): # if page contains next page, then yield request\n",
      "                yield scrapy.Request(url, callback=self.parse_book)\n",
      "\n",
      "    def parse(self, response):\n",
      "        rows =  response.xpath('//*[@id=\"mainTable\"]/tbody[3]')\n",
      "        for row in rows.css('tr'):         \n",
      "            yield {\n",
      "                'district' : row.xpath('td[1]/text()').get(),\n",
      "                'apartment_type' : row.xpath('td[2]/text()').get(),\n",
      "                'property_type' : row.xpath('td[3]/text()').get(),\n",
      "                'floor_area' : row.xpath('td[4]/text()').get(),\n",
      "                'price' : row.xpath('td[5]/text()').get(),                \n",
      "                'price_m2' : row.xpath('td[6]/text()').get(),\n",
      "                'build_year' : row.xpath('td[7]/text()').get(),\n",
      "                'floor' : row.xpath('td[8]/text()').get(),\n",
      "                'elevator' : row.xpath('td[9]/text()').get(),\n",
      "                'condition' : row.xpath('td[10]/text()').get(),\n",
      "                'plot' : row.xpath('td[11]/text()').get(),\n",
      "                'energy_class': row.xpath('td[12]/text()').get(),\n",
      "                'date_scrape': '2021-02'\n",
      "            }\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    process = CrawlerProcess({\n",
      "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
      "    })\n",
      "\n",
      "    process.crawl(QuotesSpider)\n",
      "    process.start() # the script will block here until the crawling is finished\n",
      "22/1: import scrapy\n",
      "22/2: !pip list\n",
      "22/3:\n",
      "url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format('Espoo', 1)\n",
      "time.sleep(0.15) # Set pausing time between each request\n",
      "response = requests.get(url) # Send GET request and receive response\n",
      "#content = response.text\n",
      "22/4:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "\n",
      "url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format('Espoo', 1)\n",
      "time.sleep(0.15) # Set pausing time between each request\n",
      "response = requests.get(url) # Send GET request and receive response\n",
      "#content = response.text\n",
      "22/5: response\n",
      "22/6:\n",
      "rows =  response.xpath('//*[@id=\"mainTable\"]/tbody[3]')\n",
      "for row in rows.css('tr'):         \n",
      "    yield {\n",
      "        'district' : row.xpath('td[1]/text()').get(),\n",
      "        'apartment_type' : row.xpath('td[2]/text()').get(),\n",
      "        'property_type' : row.xpath('td[3]/text()').get(),\n",
      "        'floor_area' : row.xpath('td[4]/text()').get(),\n",
      "        'price' : row.xpath('td[5]/text()').get(),                \n",
      "        'price_m2' : row.xpath('td[6]/text()').get(),\n",
      "        'build_year' : row.xpath('td[7]/text()').get(),\n",
      "        'floor' : row.xpath('td[8]/text()').get(),\n",
      "        'elevator' : row.xpath('td[9]/text()').get(),\n",
      "        'condition' : row.xpath('td[10]/text()').get(),\n",
      "        'plot' : row.xpath('td[11]/text()').get(),\n",
      "        'energy_class': row.xpath('td[12]/text()').get(),\n",
      "        'date_scrape': '2021-02'\n",
      "    }\n",
      "22/7: response\n",
      "22/8: response.text\n",
      "22/9: response.text.xpath\n",
      "22/10: response.content\n",
      "22/11: response.content.xpath\n",
      "22/12: response.content\n",
      "22/13: response.css('#next-prev-top').get()\n",
      "22/14: response.css('#next-prev-top').get()\n",
      "22/15:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "import sys\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "    print(content)\n",
      "    sys.exit()\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "22/16:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "import sys\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "22/17:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "c = 0\n",
      "i = 1\n",
      "import sys\n",
      "\n",
      "while i < 70 and c < len(cities):\n",
      "    url = \"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i)\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "22/18: results\n",
      "22/19:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) for i in range(0,2)] ]\n",
      "22/20:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) for i in range(0,2)]\n",
      "22/21: url\n",
      "22/22:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "       for i in range(0,2) and c in range(0,2)]\n",
      "22/23: cities[1]\n",
      "22/24: cities[2]\n",
      "22/25:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "i=1\n",
      "url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "       for c in range(0,2)]\n",
      "22/26: url\n",
      "22/27:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "i=1\n",
      "url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "       for c in range(0,3)]\n",
      "22/28: url\n",
      "22/29:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "i=1\n",
      "url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "       for c in range(0,3) and i in range(0,2)]\n",
      "22/30:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls_[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "        i in range(0,2)] \n",
      "    urls.apppend(url)\n",
      "22/31:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "        i in range(0,2)] \n",
      "    urls.apppend(url)\n",
      "22/32:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(cities[c], i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.apppend(url)\n",
      "22/33:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.apppend(url)\n",
      "22/34:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.append(url)\n",
      "22/35: urls\n",
      "22/36:\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.extend(url)\n",
      "22/37: urls\n",
      "22/38:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "import sys\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.extend(url)\n",
      "\n",
      "for url in urls:\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "22/39:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "request.get(url)\n",
      "22/40:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "requests.get(url)\n",
      "22/41:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "response=requests.get(url)\n",
      "22/42:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "response=requests.get(url)\n",
      "22/43:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "requests.get(url)\n",
      "22/44:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "a = requests.get(url)\n",
      "22/45:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=1000&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "22/46:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "22/47:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "url\n",
      "22/48:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "23/1:\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/1:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/2:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/3:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "import sys\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.extend(url)\n",
      "\n",
      "for url in urls:\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "24/4:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "import sys\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.extend(url)\n",
      "\n",
      "for url in urls:\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    #i += 1\n",
      "\n",
      "    # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "    last_block = bodies[tbody_len - 1].find_all('form')\n",
      "    #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "    if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "        print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "        c += 1\n",
      "        i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "24/5:\n",
      "import requests\n",
      "import time\n",
      "import csv\n",
      "from bs4 import BeautifulSoup as bsoup\n",
      "\n",
      "import sys\n",
      "\n",
      "# Create list of targeted cities\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "# List for lists to store result of parser, the 1st list is column names\n",
      "results = [['city', 'district', 'huonesto', 'talot', 'floor_area', 'vh', 'price_m2', 'built_year', 'floor', 'lift', 'condition', 'energy_rank']]\n",
      "\n",
      "# c as city, i as page number\n",
      "cities = ['Helsinki', 'Espoo', 'Vantaa']\n",
      "urls=[]\n",
      "for c in cities:\n",
      "    url = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(c, i) \\\n",
      "       for i in range(0,2)] \n",
      "    urls.extend(url)\n",
      "\n",
      "for url in urls:\n",
      "    print(url)\n",
      "    time.sleep(0.15) # Set pausing time between each request\n",
      "    response = requests.get(url) # Send GET request and receive response\n",
      "    content = response.text      # Save text part of the response  \n",
      "\n",
      "    if content.find('&#...') != -1: # Check for corruption substring\n",
      "        content = content.replace('&#...', '') # Remove substring which causes corruption for HTML parser\n",
      "        #print(\"Found and replaced corruption in page \" + str(i))\n",
      "\n",
      "    # Put string into HTML parser\n",
      "    soup = bsoup(content, 'html.parser') \n",
      "    bodies = soup.find_all('tbody') \n",
      "    tbody_len = len(bodies)\n",
      "    \n",
      "    for n in range(2, tbody_len-1):\n",
      "        records = bodies[n].find_all('tr') # Content to be parsed in in 3rd or 4th <tbody> block\n",
      "\n",
      "        # Parse main transaction content\n",
      "        for rec in records[1:]: # Ignore 1st <td> block as not needed\n",
      "            parts = rec.find_all('td')\n",
      "            tmp_list = [cities[c]]\n",
      "            for part in parts:\n",
      "                if part.string is not None:\n",
      "                    tmp_list.append(part.string) \n",
      "                else:\n",
      "                    tmp_list.append(\"\") # Avoid saving none value as binary value\n",
      "            results.append(tmp_list)\n",
      "    #i += 1\n",
      "\n",
      "#     # Check if next page exists, if next page exists, there will be 2 <form> blocks within 4th <tbody> block\n",
      "#     last_block = bodies[tbody_len - 1].find_all('form')\n",
      "#     #print(\"Page {}, last block {}\".format(i-1, len(last_block)))\n",
      "#     if (i-1) != 1 and len(last_block) < 2: # If it is last page, move to next city and return to 1st page\n",
      "#         print(\"Finished \" + cities[c] + \" with \" + str(i - 1) + \" pages\")\n",
      "#         c += 1\n",
      "#         i = 1\n",
      "\n",
      "\n",
      "with open('asunto_sec.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(results)\n",
      "    f.close()\n",
      "24/6:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/7:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "url = 'google.com'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/8:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "url = 'https://www.google.com/'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/9:\n",
      "import requests\n",
      "import lxml.html as lh\n",
      "import pandas as pd\n",
      "24/10: requests.get(url)\n",
      "24/11: requests.get(url)\n",
      "24/12: requests.get(url)\n",
      "24/13:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=80&search=1&sf=0&so=a'\n",
      "#url = 'https://www.google.com/'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/14: requests.get(url)\n",
      "24/15: a = requests.get(url)\n",
      "24/16: a\n",
      "24/17: a.content\n",
      "24/18:\n",
      "soup = bsoup(a, 'html.parser') \n",
      "bodies = soup.find_all('tbody')\n",
      "24/19: a\n",
      "24/20: a.content()\n",
      "24/21: a.content\n",
      "24/22:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('tbody')\n",
      "24/23: bodies\n",
      "24/24:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('next-prev-top')\n",
      "24/25: bodies\n",
      "24/26:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('tbody')\n",
      "24/27: bodies\n",
      "24/28:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('pagination')\n",
      "24/29: bodies\n",
      "24/30: soup\n",
      "24/31:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('table ')\n",
      "24/32: bodies\n",
      "24/33:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('table')\n",
      "24/34: bodies\n",
      "24/35:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=90&search=1&sf=0&so=a'\n",
      "#url = 'https://www.google.com/'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/36: a = requests.get(url)\n",
      "24/37:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('table')\n",
      "24/38: bodies\n",
      "24/39: bodies\n",
      "24/40:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('form')\n",
      "24/41: bodies\n",
      "24/42:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('//*[@id=\"mainTable\"]/tbody[1]')\n",
      "24/43: bodies\n",
      "24/44:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=10&search=1&sf=0&so=a'\n",
      "#url = 'https://www.google.com/'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/45: a = requests.get(url)\n",
      "24/46:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('//*[@id=\"mainTable\"]/tbody[1]')\n",
      "24/47: bodies\n",
      "24/48: soup\n",
      "24/49:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all(attrs{'input':'seurava sivu'})\n",
      "24/50:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all(attrs={'input':'seurava sivu'})\n",
      "24/51: soup\n",
      "24/52: bodies\n",
      "24/53: soup\n",
      "24/54:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=100&search=1&sf=0&so=a'\n",
      "#url = 'https://www.google.com/'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/55: a = requests.get(url)\n",
      "24/56: requests.get(url)\n",
      "24/57: soup\n",
      "24/58:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all(attrs={'input':'seuraava sivu'})\n",
      "24/59: bodies\n",
      "24/60:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all(attrs={'seuraava sivu'})\n",
      "24/61: bodies\n",
      "24/62:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('seuraava sivu')\n",
      "24/63: bodies\n",
      "24/64:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('submit')\n",
      "24/65: bodies\n",
      "24/66:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input')\n",
      "24/67: bodies\n",
      "24/68:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit'})\n",
      "24/69: bodies\n",
      "24/70:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'value':'Suomeksi'})\n",
      "24/71: bodies\n",
      "24/72:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'value':'\"seuraava sivu \"'})\n",
      "24/73: bodies\n",
      "24/74:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','value':'\"seuraava sivu \"'})\n",
      "24/75: bodies\n",
      "24/76:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','value':\"seuraava sivu \"})\n",
      "24/77: bodies\n",
      "24/78:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','value':\"seuraava sivu\"})\n",
      "24/79: bodies\n",
      "24/80:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit',name=\"submit\" ,type=\"submit\"})\n",
      "24/81:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','name':\"submit\" ,'type':\"submit\"})\n",
      "24/82: bodies\n",
      "24/83:\n",
      "import requests\n",
      "url = 'https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=0&z=10&search=1&sf=0&so=a'\n",
      "#url = 'https://www.google.com/'\n",
      "#a = requests.get(url)\n",
      "print(url)\n",
      "24/84: a = requests.get(url)\n",
      "24/85: requests.get(url)\n",
      "24/86:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','name':\"submit\" ,'type':\"submit\"})\n",
      "24/87: bodies\n",
      "24/88:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','name':\"submit\" ,'type':\"submit\", \"value\":\"seuraava sivu\"})\n",
      "24/89: bodies\n",
      "24/90:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','name':\"submit\" ,'type':\"submit\", })\n",
      "24/91: bodies\n",
      "24/92:\n",
      "soup = bsoup(a.content, 'html.parser') \n",
      "bodies = soup.find_all('input', attrs={'class':'submit','name':\"submit\" ,'type':\"submit\",'value':\"seuraava sivu \" })\n",
      "24/93: bodies\n",
      "24/94: pd.read_csv('./src/price_spider/test.csv')\n",
      "24/95: pd.read_csv('../src/price_spider/test.csv')\n",
      "24/96: pd.read_csv('../src/price_spider/test.csv')\n",
      "24/97: df = pd.read_csv('../src/price_spider/test.csv')\n",
      "24/98:\n",
      "df = pd.read_csv('../src/price_spider/test.csv')\n",
      "\n",
      "df.head(20)\n",
      "24/99:\n",
      "df = pd.read_csv('../src/price_spider/test.csv')\n",
      "\n",
      "df.tail(20)\n",
      "24/100:\n",
      "df = pd.read_csv('../src/price_spider/test.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/101:\n",
      "df = pd.read_csv('../src/price_spider/test.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/102:\n",
      "df = pd.read_csv('../src/price_spider/test1.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/103:\n",
      "    cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "    start_urls = []\n",
      "#     start_urls = [\n",
      "#         f\"https://asuntojen.hintatiedot.fi/haku/?c={c}&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "#        # f\"https://asuntojen.hintatiedot.fi/haku/?c=Espoo&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2),\n",
      "#        # f\"https://asuntojen.hintatiedot.fi/haku/?c=Helsinki&cr=1&t=3&l=2&z={i}&search=1\" for i in range(0, 2)\n",
      "#     ]\n",
      "\n",
      "    for city in cities:\n",
      "        print('++++++++++++++++++++++++++++++++++++++++++')\n",
      "        print(city)\n",
      "        urls = [\"https://asuntojen.hintatiedot.fi/haku/?c={}&cr=1&t=3&l=0&z={}&search=1&sf=0&so=a\".format(city, i) for i in range(0,2)]\n",
      "        start_urls.extend(urls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/104: start_urls\n",
      "24/105:\n",
      "df = pd.read_csv('../src/price_spider/test1.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/106:\n",
      "df = pd.read_csv('../src/price_spider/test1.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/107:\n",
      "df = pd.read_csv('../src/price_spider/test2.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/108:\n",
      "df = pd.read_csv('../src/price_spider/test2.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/109:\n",
      "# //*[@id=\"mainTable\"]/tbody[2]\n",
      "\n",
      "response.url\n",
      "24/110:\n",
      "df = pd.read_csv('../src/price_spider/test2.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/111:\n",
      "df = pd.read_csv('../src/price_spider/test2.csv')\n",
      "\n",
      "df.tail(30)\n",
      "24/112:\n",
      "df = pd.read_csv('../src/price_spider/test2.csv', sep=',')\n",
      "\n",
      "df.tail(30)\n",
      "24/113:\n",
      "from datetime import datetime\n",
      "datetime.today\n",
      "24/114:\n",
      "from datetime import datetime\n",
      "datetime.today()\n",
      "24/115:\n",
      "from datetime import datetime\n",
      "datetime.today('%d-%m-%Y')\n",
      "24/116:\n",
      "from datetime import datetime\n",
      "datetime.today(strf='%d-%m-%Y')\n",
      "24/117:\n",
      "from datetime import date\n",
      "date.today(strf='%d-%m-%Y')\n",
      "24/118:\n",
      "from datetime import date\n",
      "date.today()\n",
      "24/119:\n",
      "from datetime import date\n",
      "date.today\n",
      "24/120:\n",
      "from datetime import date\n",
      "date.today.strftime(\"%d/%m/%Y\")\n",
      "24/121:\n",
      "from datetime import date\n",
      "date.today.strftime(\"%d/%m/%Y\")\n",
      "24/122:\n",
      "from datetime import date\n",
      "date.today().strftime(\"%d/%m/%Y\")\n",
      "24/123:\n",
      "df = pd.read_csv('../src/price_spider/test.csv', sep=',')\n",
      "\n",
      "df.tail(30)\n",
      "24/124: df.shape\n",
      "24/125:\n",
      "df = pd.read_csv('../src/price_spider/test.csv', sep=',')\n",
      "\n",
      "df.shape\n",
      "24/126: uel = '    # https://asunnot.oikotie.fi/myytavat-asunnot?pagination=1&locations=%5B%5B64,6,%22Helsinki%22%5D,%5B39,6,%22Espoo%22%5D,%5B65,6,%22Vantaa%22%5D%5D&cardType=100&buildingType%5B%5D=1&buildingType%5B%5D=256&buildingType%5B%5D=2&buildingType%5B%5D=64&buildingType%5B%5D=4&buildingType%5B%5D=8&buildingType%5B%5D=32&buildingType%5B%5D=128&habitationType%5B%5D=1'\n",
      "24/127: request.get(url)\n",
      "24/128:\n",
      "\n",
      "requests.get(url)\n",
      "24/129: a\n",
      "24/130: soup = bsoup(a, 'html.parser')\n",
      "24/131: soup = bsoup(a.text(), 'html.parser')\n",
      "24/132: soup = bsoup(a.text, 'html.parser')\n",
      "24/133: soup\n",
      "24/134: b= '/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button/span/font/font'\n",
      "24/135: bs4.BeautifulSoup('b')\n",
      "24/136: bsoup.BeautifulSoup('b')\n",
      "24/137:\n",
      "import bs4\n",
      "bs4.BeautifulSoup('b')\n",
      "24/138:\n",
      "import bs4\n",
      "bs4.BeautifulSoup('b').text()\n",
      "24/139:\n",
      "import bs4\n",
      "bs4.BeautifulSoup('b').text\n",
      "24/140:\n",
      "import bs4\n",
      "bs4.BeautifulSoup(b).text\n",
      "24/141: soup = bsoup(a.response, 'html.parser')\n",
      "24/142: soup = bsoup(a.response, 'html.parser')\n",
      "24/143: soup = bsoup(a.text, 'html.parser')\n",
      "24/144:\n",
      "import bs4\n",
      "bs4.BeautifulSoup(soup).text\n",
      "24/145:\n",
      "import bs4\n",
      "bs4.BeautifulSoup(a).text\n",
      "24/146: soup\n",
      "24/147: soup\n",
      "24/148: soup.find_all('button')\n",
      "24/149: soup = bsoup(a.text, 'html.parser')\n",
      "24/150: soup.find_all('button')\n",
      "24/151: soup.find_all('pagination')\n",
      "24/152: soup.find_all('pagination')\n",
      "24/153: uel = '    # https://asunnot.oikotie.fi/myytavat-asunnot?pagination=1&locations=%5B%5B64,6,%22Helsinki%22%5D,%5B39,6,%22Espoo%22%5D,%5B65,6,%22Vantaa%22%5D%5D&cardType=100&buildingType%5B%5D=1&buildingType%5B%5D=256&buildingType%5B%5D=2&buildingType%5B%5D=64&buildingType%5B%5D=4&buildingType%5B%5D=8&buildingType%5B%5D=32&buildingType%5B%5D=128&habitationType%5B%5D=1'\n",
      "24/154:\n",
      "\n",
      "a = requests.get(url)\n",
      "24/155: soup = bsoup(a.text, 'html.parser')\n",
      "24/156: soup.find_all('pagination')\n",
      "24/157: soup.find_all('td')\n",
      "24/158: soup.find_all('pagination ng-if')\n",
      "24/159: soup\n",
      "24/160:\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "24/161:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "24/162:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a, htmlparser)\n",
      "24/163:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a, htmlparser)\n",
      "24/164: a\n",
      "24/165:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.response, htmlparser)\n",
      "24/166: a\n",
      "24/167: a.text\n",
      "24/168: a.response\n",
      "24/169:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.content, htmlparser)\n",
      "24/170:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "24/171:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "\n",
      "tree.xpath(b)\n",
      "24/172:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "tree.xpath(b)\n",
      "24/173: b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button/span/font'\n",
      "24/174:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "tree.xpath(b)\n",
      "24/175:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "tree.xpath(b).text\n",
      "24/176: b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button/span/font/font'\n",
      "24/177:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "tree.xpath(b).text\n",
      "24/178: tree.xpath('//p[contains(text(),\"1 /\")]/text()')\n",
      "24/179:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "tree.xpath(b).text\n",
      "24/180: tree.xpath('//p[contains(text(),\"1 /\")]/text()')\n",
      "24/181:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "tree.xpath(b).text\n",
      "tree.xpath('//p[contains(text(),\"1 /\")]/text()')\n",
      "24/182:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "#tree.xpath(b).text\n",
      "tree.xpath('//p[contains(text(),\"1 /\")]/text()')\n",
      "24/183: soup.find_all('ul')\n",
      "24/184: soup.find_all('li')\n",
      "24/185: soup.find_all('div', attrs={'class':'pagination__control'})\n",
      "24/186: soup.find_all('div')\n",
      "24/187: soup.find_all('pagination')\n",
      "24/188: soup.find_all('li')\n",
      "24/189: soup.find_all('button')\n",
      "24/190: url = '    # https://asunnot.oikotie.fi/myytavat-asunnot?pagination=1&locations=%5B%5B64,6,%22Helsinki%22%5D,%5B39,6,%22Espoo%22%5D,%5B65,6,%22Vantaa%22%5D%5D&cardType=100&buildingType%5B%5D=1&buildingType%5B%5D=256&buildingType%5B%5D=2&buildingType%5B%5D=64&buildingType%5B%5D=4&buildingType%5B%5D=8&buildingType%5B%5D=32&buildingType%5B%5D=128&habitationType%5B%5D=1'\n",
      "24/191:\n",
      "\n",
      "a = requests.get(url)\n",
      "24/192: url='https://asunnot.oikotie.fi/myytavat-asunnot?pagination=1&locations=%5B%5B64,6,%22Helsinki%22%5D,%5B39,6,%22Espoo%22%5D,%5B65,6,%22Vantaa%22%5D%5D&cardType=100&buildingType%5B%5D=1&buildingType%5B%5D=256&buildingType%5B%5D=2&buildingType%5B%5D=64&buildingType%5B%5D=4&buildingType%5B%5D=8&buildingType%5B%5D=32&buildingType%5B%5D=128&habitationType%5B%5D=1'\n",
      "24/193:\n",
      "\n",
      "a = requests.get(url)\n",
      "24/194: soup = bsoup(a.text, 'html.parser')\n",
      "24/195: soup.find_all('pagination ng-if')\n",
      "24/196: soup.find_all('pagination')\n",
      "24/197: soup.find_all('button')\n",
      "24/198:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "#tree.xpath(b).text\n",
      "tree.xpath('//p[contains(text(),\"1 /\")]/text()')\n",
      "24/199:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "#tree.xpath(b).text\n",
      "tree.xpath('//p[contains(text(),\"Go to\")]/text()')\n",
      "24/200: soup.find_all('button' attrs={'class':'button pagination__page'})\n",
      "24/201: soup.find_all('button', attrs={'class':'button pagination__page'})\n",
      "24/202:\n",
      "soup.find_all('button', attrs={'class':'button pagination__page'})\n",
      "\n",
      "soup.find_all('class')\n",
      "24/203:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "#tree.xpath(b).text\n",
      "tree.xpath('//p[contains(text(),\"button pagination__page\")]/text()')\n",
      "24/204:\n",
      "soup.find_all('button', attrs={'class':'button pagination__page'})\n",
      "\n",
      "soup.find_all('button')\n",
      "24/205:\n",
      "from lxml import etree\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(a.text, htmlparser)\n",
      "#b='/html/body/main/listing-search/section[2]/div/div/div/pagination/div/ul/li[6]/button'\n",
      "#tree.xpath(b).text\n",
      "tree.css('div.pagination')\n",
      "24/206:\n",
      "soup.find_all('button', attrs={'class':'button pagination__page'})\n",
      "\n",
      "soup.find_all('href')\n",
      "25/1:\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/2:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "import sqlalchemy\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/3:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/4: soup\n",
      "25/5: links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "25/6: links_with_text\n",
      "25/7:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "i=1\n",
      "while soup.p == None:\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "    i = i+10\n",
      "    url_1 = url + str(i)\n",
      "    page = requests.get(url_1)  \n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "pages = [url + str(page_num) for page_num in range(1, i-2)] \n",
      "#page = requests.get(url)\n",
      "#soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/8:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "i=1\n",
      "while soup.p == None:\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "    i = i+10\n",
      "    url_1 = url + str(i)\n",
      "    page = requests.get(url_1)  \n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "pages = [url + str(page_num) for page_num in range(1, i-2)] \n",
      "#page = requests.get(url)\n",
      "#soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/9: pages\n",
      "25/10:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "i=1\n",
      "\n",
      "while soup.p == None:\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "    i = i+10\n",
      "    url_1 = url + str(i)\n",
      "    page = requests.get(url_1)  \n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "pages = [url + str(page_num) for page_num in range(1, i-2)] \n",
      "#page = requests.get(url)\n",
      "#soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/11:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "i=1\n",
      "\n",
      "while soup.p == None:\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu='\n",
      "    i = i+10\n",
      "    url_1 = url + str(i)\n",
      "    page = requests.get(url_1)  \n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "pages = [url + str(page_num) for page_num in range(1, i-2)] \n",
      "#page = requests.get(url)\n",
      "#soup = BeautifulSoup(page.content, 'html.parser')\n",
      "25/12: pages\n",
      "25/13: page\n",
      "25/14: pages\n",
      "25/15: soup\n",
      "25/16:\n",
      "# identify number of pages that need to loop over\n",
      "url='https://www.spacelist.ca/listings/bc/vancouver/b/c4q79p60we/dkvrw7q74u/page/1'\n",
      "#url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "i=1\n",
      "\n",
      "while soup.p == None:\n",
      "    url = \"https://www.spacelist.ca/listings/bc/vancouver/b/c4q79p60we/dkvrw7q74u/page/\"\n",
      "    i = i+10\n",
      "    url_1 = url + str(i)\n",
      "    page = requests.get(url_1)  \n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "pages = [url + str(page_num) for page_num in range(1, i-2)]\n",
      "25/17: soup.p\n",
      "25/18: soup\n",
      "25/19: soup.p\n",
      "25/20:\n",
      "response = urlopen(url)\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "tree.xpath(xpathselector)\n",
      "25/21:\n",
      "import urllib\n",
      "import urllib2\n",
      "response = urlopen(url)\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "tree.xpath(xpathselector)\n",
      "25/22:\n",
      "import urllib\n",
      "#import urllib2\n",
      "response = urlopen(url)\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "tree.xpath(xpathselector)\n",
      "25/23:\n",
      "\n",
      "response = requests.get(url)\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "tree.xpath(xpathselector)\n",
      "25/24:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/25:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url).text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/26:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "response = response.text()\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/27:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/28:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "#response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/29:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "#response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response.text, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/30:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "#response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response.content, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/31:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "#response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response.text, htmlparser)\n",
      "#tree.xpath(xpathselector)\n",
      "25/32:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "#response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response.text, htmlparser)\n",
      "tree.xpath(xpath)\n",
      "25/33:\n",
      "from lxml import etree\n",
      "\n",
      "response = requests.get(url)\n",
      "#response = response.text\n",
      "htmlparser = etree.HTMLParser()\n",
      "tree = etree.parse(response.text, htmlparser)\n",
      "25/34: soup\n",
      "25/35:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas.core.common import flatten\n",
      "\n",
      "import re\n",
      "import os\n",
      "\n",
      "\n",
      "from tqdm import tqdm\n",
      "import time\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup \n",
      "import requests\n",
      "\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "i=1\n",
      "25/36: soup\n",
      "25/37: soup.find('button')\n",
      "25/38: soup.find_all('button')\n",
      "25/39: soup.find_all('button', attrs={'data-react-toolbox':'button'})\n",
      "25/40: soup.find_all('button', attrs={'data-react-toolbox':'button', 'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/41:\n",
      "soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\\\n",
      ".text\n",
      "25/42:\n",
      "soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\\\n",
      ".text()\n",
      "25/43:\n",
      "soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\\\n",
      "25/44:\n",
      "soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/45:\n",
      "soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'}).text\n",
      "25/46:\n",
      "soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/47:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/48: page\n",
      "25/49: page.get_text()\n",
      "25/50: page.find_all()\n",
      "25/51: page\n",
      "25/52:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'}, text=True)\n",
      "25/53: page\n",
      "25/54:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Paginati\n",
      "                            )\n",
      "25/55:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'}, text=True)\n",
      "25/56: page\n",
      "25/57:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/58: page.\n",
      "25/59: page\n",
      "25/60: page.sort()\n",
      "25/61: page.content\n",
      "25/62:\n",
      "page=soup.find('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/63: page.content\n",
      "25/64: page.content\n",
      "25/65: page\n",
      "25/66:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/67: page\n",
      "25/68: page[2]\n",
      "25/69: page[2].get_text()\n",
      "25/70: [i.get_text() for i in page]\n",
      "25/71: [int(i.get_text()) for i in page]\n",
      "25/72:\n",
      "page = [int(i.get_text()) for i in page]\n",
      "page.max()\n",
      "25/73:\n",
      "page = [int(i.get_text()) for i in page]\n",
      "max(page)\n",
      "25/74:\n",
      "page = [int(i.get_text()) for i in page]\n",
      "np.max(page)\n",
      "25/75:\n",
      "page = [i.get_text() for i in page]\n",
      "np.max(page)\n",
      "25/76:\n",
      "page = [i.get_text() for i in page]\n",
      "page\n",
      "25/77:\n",
      "page = [i.get_text() for i in page]\n",
      "page\n",
      "25/78:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/79:\n",
      "page = [i.get_text() for i in page]\n",
      "page\n",
      "25/80:\n",
      "page = [int(i.get_text()) for i in page]\n",
      "page\n",
      "25/81:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/82:\n",
      "page = [int(i.get_text()) for i in page]\n",
      "page\n",
      "25/83:\n",
      "page=soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "25/84:\n",
      "page = [int(i.get_text()) for i in page]\n",
      "max(page)\n",
      "25/85: page\n",
      "25/86: max_page\n",
      "25/87:\n",
      "max_page = max(page)\n",
      "max_page\n",
      "25/88:\n",
      "# find href in the each page\n",
      "max_page = 2\n",
      "unit_pages =[] \n",
      "for page in tqdm(max_page):\n",
      "    page = requests.get(page)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.append(links_with_text)\n",
      "25/89:\n",
      "# find href in the each page\n",
      "max_page = 2\n",
      "url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(page)'\n",
      "unit_pages =[] \n",
      "for page in tqdm(max_page):\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.append(links_with_text)\n",
      "25/90:\n",
      "# find href in the each page\n",
      "max_page = 2\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(max_page):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.append(links_with_text)\n",
      "25/91:\n",
      "# find href in the each page\n",
      "max_page = 2\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.append(links_with_text)\n",
      "25/92: unit_pages\n",
      "25/93:\n",
      "#\n",
      "\n",
      "r = requests.get('https://www.etuovi.com/kohde/20869323?haku=M1611637313')\n",
      "25/94: r.response\n",
      "25/95: r.response()\n",
      "25/96: r.response()\n",
      "25/97: r.text()\n",
      "25/98: r.text\n",
      "25/99: r.content\n",
      "25/100: soup = BeautifulSoup(r.content, 'html.parser')\n",
      "25/101: soup\n",
      "25/102: soup.find('title')\n",
      "25/103: soup.find('meta content')\n",
      "25/104: soup.find('meta')\n",
      "25/105: soup.find('meta content')\n",
      "25/106: soup.find_all('meta content')\n",
      "25/107: soup.find_all('meta-content')\n",
      "25/108: soup.find_all('meta#content')\n",
      "25/109: soup.find_all('meta.content')\n",
      "25/110: soup.find_all('div.ItemSummary')\n",
      "25/111: soup.find_all('div')\n",
      "25/112: soup.find_all('div.flexboxgrid__col-xs-12__1I1LS.ItemSummaryContainer__itemTitleContainer__cDLuQ')\n",
      "25/113: soup.find_all('flexboxgrid__col-xs-12__1I1LS.ItemSummaryContainer__itemTitleContainer__cDLuQ')\n",
      "25/114: soup.find_all('Meta')\n",
      "25/115: soup.find_all('content')\n",
      "25/116: soup.find_all('content')\n",
      "25/117: soup.find_all('meta,content')\n",
      "25/118: soup.find_all('meta.content')\n",
      "25/119: soup.find_all('meta')\n",
      "25/120: soup.find('div', class_=' div.flexboxgrid__col-xs-12__1I1LS.flexboxgrid__col-sm-12__3lVf6.flexboxgrid__col-md-8__161oS.flexboxgrid__col-lg-8__2H2vd')\n",
      "25/121: soup.find('div', class_='flexboxgrid__col-xs-12__1I1LS.flexboxgrid__col-sm-12__3lVf6.flexboxgrid__col-md-8__161oS.flexboxgrid__col-lg-8__2H2vd')\n",
      "25/122: soup.find('div', class_='flexboxgrid__col-xs-12__1I1LS.flexboxgrid__col-sm-12__3lVf6')\n",
      "25/123: soup.find('div')\n",
      "25/124: soup.find_all('div', class_='flexboxgrid__col-xs-12__1I1LS.flexboxgrid__col-sm-12__3lVf6.flexboxgrid__col-md-8__161oS.flexboxgrid__col-lg-8__2H2vd')\n",
      "25/125: soup.find_all('div', class_='flexboxgrid__col-xs-12__1I1LS')\n",
      "25/126: soup.find_all('div', class_='flexboxgrid__col-xs-12__1I1LS.flexboxgrid__col-sm-12__3lVf6')\n",
      "25/127: soup.find_all('div', class_='flexboxgrid__col-xs-12__1I1LS')\n",
      "25/128: soup.find_all('div', class_='flexboxgrid__col-xs-12__1I1LS').find('flexboxgrid__col-sm-12__3lVf6')\n",
      "25/129: soup.find_all('div', class_='flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\"><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Kohdenumero</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">20869323<br></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Sijainti</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\"><ul><li><a data-react-toolbox=\"link\" class=\"theme__link__E9m4k InfoSegment__noStyleLink__2e28Y\" target=\"_blank\" href=\"/myytavat-asunnot/vantaa\"><abbr>Vantaa</abbr></a><span>&nbsp;<a data-react-toolbox=\"link\" class=\"theme__link__E9m4k InfoSegment__noStyleLink__2e28Y\" target=\"_blank\" href=\"/myytavat-asunnot/vantaa/jokiniemi\"><abbr>Jokiniemi</abbr></a></span></li><li>Gammelkullantanhua 1<!-- -->, <!-- -->01370 Vantaa</li></ul></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Tyyppi</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\"><a data-react-toolbox=\"link\" class=\"theme__link__E9m4k InfoSegment__noStyleLink__2e28Y\" target=\"_blank\" href=\"/myytavat-asunnot/vantaa/luhtitalo\"><abbr>Luhtitalo</abbr></a>&nbsp;<!-- -->(huoneisto)</div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Omistusmuoto</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\"><a data-react-toolbox=\"link\" class=\"theme__link__E9m4k InfoSegment__noStyleLink__2e28Y\" target=\"_blank\" href=\"/myytavat-asunnot/vantaa/omistusasunnot\"><abbr>Omistusasunto</abbr></a></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Huoneistoselitelm</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">3h + k + s<br></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Huoneita</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\"><a data-react-toolbox=\"link\" class=\"theme__link__E9m4k InfoSegment__noStyleLink__2e28Y\" target=\"_blank\" href=\"/myytavat-asunnot/vantaa/3-huonetta\"><abbr>3 huonetta</abbr></a></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Asuintilojen pinta-ala</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\"><span>52<!-- --> m</span></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Kokonaispinta-ala</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\"><span>52<!-- --> m</span></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Listietoja pinta-alasta</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">yhtijrjestyksen mukainen, isnnitsijntodistuksen mukainen<br></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Kerrokset</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">1/1<br></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Asuinkerrosten mr</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">1<br></div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Rakennusvuosi</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">2018</div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Kyttnottovuosi</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">2018</div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Vapautuminen</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4')\n",
      "25/130: soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\">2018</div></div><div class=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\"><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\"><em>Vapautuminen</em></div><div class=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4')\n",
      "25/131: soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-8__2jfMv CompactInfoRow__content__3jGt4\")\n",
      "25/132: soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "25/133: title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "25/134:\n",
      "title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/135:\n",
      "title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "\n",
      "title\n",
      "25/136:\n",
      "title = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/137:\n",
      "title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "len([i.get_text() for i in title])\n",
      "25/138:\n",
      "title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "len([i.get_text() for i in title])\n",
      "25/139:\n",
      "title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/140:\n",
      "title = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/141:\n",
      "title = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/142:\n",
      "title = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "len([i.get_text() for i in title])\n",
      "25/143:\n",
      "title = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/144:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "[i.get_text() for i in title]\n",
      "25/145:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "[i.get_text() for i in k]\n",
      "25/146:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "{[i.get_text() for i in k]: [i.get_text() for i in v] }\n",
      "25/147:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "# extract test\n",
      "k = [i.get_text() for i in k]\n",
      "v = [i.get_text() for i in v]\n",
      "\n",
      " {k[i]: v[i] for i in range(len(k))}\n",
      "25/148:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\n",
      "# CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\n",
      "# flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-12__3lVf6 flexboxgrid__col-md-8__161oS flexboxgrid__col-lg-8__2H2vd\n",
      "\n",
      "# extract test\n",
      "k = [i.get_text() for i in k]\n",
      "v = [i.get_text() for i in v]\n",
      "\n",
      "{k[i]: v[i] for i in range(len(k))}\n",
      "25/149: unit_pages\n",
      "25/150: [page for page in unit_pages if '/kohde/' in page]\n",
      "25/151:\n",
      "[page for page in unit_pages if '/kohde/' in page]\n",
      "unit_pages\n",
      "25/152:\n",
      "[page for page in unit_pages if '/kohde/' in page]\n",
      "unit_pages\n",
      "25/153:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "unit_pages\n",
      "25/154:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "#unit_pages\n",
      "25/155:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "unit_pages\n",
      "#unit_pages\n",
      "25/156:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kohde' in i]\n",
      "#unit_pages\n",
      "25/157:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kohde' in i]\n",
      "unit_pages\n",
      "25/158:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kirjaudu' in i]\n",
      "unit_pages\n",
      "25/159:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "#[i for i in unit_pages if 'kirjaudu' in i]\n",
      "unit_pages\n",
      "25/160:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kirjaudu' in i]\n",
      "#unit_pages\n",
      "25/161:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kirjaudu' in unit_pages]\n",
      "#unit_pages\n",
      "25/162:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'k' in unit_pages]\n",
      "#unit_pages\n",
      "25/163:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'k' in unit_pages]\n",
      "unit_pages\n",
      "25/164:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "max_page = 3\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.append(links_with_text)\n",
      "25/165:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'k' in unit_pages]\n",
      "unit_pages\n",
      "25/166:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "max_page = 3\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.extend(links_with_text)\n",
      "25/167:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'k' in unit_pages]\n",
      "unit_pages\n",
      "25/168:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kohde' in unit_pages]\n",
      "25/169:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kohde' in unit_pages]\n",
      "25/170:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "[i for i in unit_pages if 'kohde' in unit_pages]\n",
      "\n",
      "unit_pages\n",
      "25/171:\n",
      "[page for page in unit_pages if 'kohde' in page]\n",
      "\n",
      "#[i for i in unit_pages if 'kohde' in unit_pages]\n",
      "\n",
      "#unit_pages\n",
      "25/172:\n",
      "# filer\n",
      "['https://www.etuovi.com/'+page for page in unit_pages if 'kohde' in page]\n",
      "25/173:\n",
      "# filer\n",
      "set(['https://www.etuovi.com/'+page for page in unit_pages if 'kohde' in page])\n",
      "25/174:\n",
      "# filer\n",
      "list(set(['https://www.etuovi.com/'+page for page in unit_pages if 'kohde' in page]))\n",
      "25/175:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "max_page = 3\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.extend(links_with_text)\n",
      "    \n",
      "# filter only relevant href and contact the domain names\n",
      "all_pages = list(set(['https://www.etuovi.com/'+page for page in unit_pages if 'kohde' in page]))\n",
      "25/176:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "\n",
      "# extract test\n",
      "k = [i.get_text() for i in k]\n",
      "v = [i.get_text() for i in v]\n",
      "\n",
      "row = {k[i]: v[i] for i in range(len(k))}\n",
      "25/177: row\n",
      "25/178: k\n",
      "25/179:\n",
      "#\n",
      "\n",
      "r = requests.get('https://www.etuovi.com/kohde/20869323?haku=M1611637313')\n",
      "25/180: soup = BeautifulSoup(r.content, 'html.parser')\n",
      "25/181:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "\n",
      "# extract test\n",
      "k = [i.get_text() for i in k]\n",
      "v = [i.get_text() for i in v]\n",
      "\n",
      "row = {k[i]: v[i] for i in range(len(k))}\n",
      "25/182: row\n",
      "25/183:\n",
      "# establish a dict for our result\n",
      "results = {}\n",
      "\n",
      "r = requests.get('https://www.etuovi.com/kohde/20869323?haku=M1611637313')\n",
      "25/184: results.append(row)\n",
      "25/185: results.update(row)\n",
      "25/186: results\n",
      "25/187: soup = BeautifulSoup(r.content, 'html.parser')\n",
      "25/188:\n",
      "k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "\n",
      "# extract test\n",
      "k = [i.get_text() for i in k]\n",
      "v = [i.get_text() for i in v]\n",
      "\n",
      "row = {k[i]: v[i] for i in range(len(k))}\n",
      "25/189: results.update(row)\n",
      "25/190: results\n",
      "25/191: results.update(row)\n",
      "25/192: results\n",
      "25/193: results = results.update(row)\n",
      "25/194: results\n",
      "25/195: results\n",
      "25/196: results.update(row)\n",
      "25/197:\n",
      "# establish a dict for our result\n",
      "results = {}\n",
      "\n",
      "r = requests.get('https://www.etuovi.com/kohde/20869323?haku=M1611637313')\n",
      "25/198: results.update(row)\n",
      "25/199: results\n",
      "25/200:\n",
      "# establish a dict for our result\n",
      "results = []\n",
      "\n",
      "r = requests.get('https://www.etuovi.com/kohde/20869323?haku=M1611637313')\n",
      "25/201: results.append(row)\n",
      "25/202: results\n",
      "25/203: results.append(row)\n",
      "25/204: results\n",
      "25/205: pd.DataFrame(results)\n",
      "25/206: import random.randint as rand\n",
      "25/207:\n",
      "import random\n",
      "randrange(0, 101, 2)\n",
      "25/208:\n",
      "from random import randrange\n",
      "randrange(0, 101, 2)\n",
      "25/209:\n",
      "from random import randrange\n",
      "randrange(0, 10, 2)\n",
      "25/210:\n",
      "from random import randrange\n",
      "randrange(0, 10, 1)\n",
      "25/211:\n",
      "from random import randrange\n",
      "randrange(0, 10, 1)\n",
      "25/212:\n",
      "from random import randrange\n",
      "randrange(0, 10, 1)\n",
      "25/213:\n",
      "from random import randrange\n",
      "randrange(0, 10, 1)\n",
      "25/214:\n",
      "from random import randrange\n",
      "randrange(0, 10, 1)\n",
      "25/215:\n",
      "from random import randrange\n",
      "randrange(0.5, 5, 1)\n",
      "25/216:\n",
      "from random import randrange\n",
      "randrange(1.5, 5, 1)\n",
      "25/217:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/218:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/219:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/220:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/221:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/222:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/223:\n",
      "from random import randrange\n",
      "randrange(1, 5, 1)\n",
      "25/224:\n",
      "from random import random\n",
      "randrange(1, 5, 1)\n",
      "25/225: random()\n",
      "25/226: random()\n",
      "25/227: random()\n",
      "25/228: random()\n",
      "25/229: random()\n",
      "25/230: random()\n",
      "25/231: random()\n",
      "25/232: random()\n",
      "25/233: random()\n",
      "25/234: from random import uniform\n",
      "25/235: uniform(2.5, 10.0)\n",
      "25/236: uniform(1, 5)\n",
      "25/237: uniform(1, 5)\n",
      "25/238: uniform(0.2, 5)\n",
      "25/239: uniform(0.2, 5)\n",
      "25/240: uniform(0.2, 5)\n",
      "25/241: uniform(0.2, 4)\n",
      "25/242: uniform(0.2, 4)\n",
      "25/243: uniform(0.2, 4)\n",
      "25/244: uniform(0.2, 4)\n",
      "25/245: uniform(0.2, 4)\n",
      "25/246: uniform(0.2, 4)\n",
      "25/247: uniform(0.2, 4)\n",
      "25/248:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "max_page = 3\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.extend(links_with_text)\n",
      "    \n",
      "# filter only relevant href and contact the domain names\n",
      "all_pages = list(set(['https://www.etuovi.com/'+page for page in unit_pages if 'kohde' in page]))\n",
      "25/249:\n",
      "# establish a list to store our result\n",
      "results = []\n",
      "for page in all_pages:\n",
      "    # send a request\n",
      "    r = requests.get(page)\n",
      "    soup = BeautifulSoup(r.content, 'html.parser')\n",
      "    \n",
      "    # extract title and value of the html results:\n",
      "    k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "    v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "    k = [i.get_text() for i in k]\n",
      "    v = [i.get_text() for i in v]\n",
      "    \n",
      "    row = {k[i]: v[i] for i in range(len(k))} \n",
      "    # append result to our results\n",
      "    results.append(row)\n",
      "    \n",
      "    sys.sleep(uniform(0.1, 4))\n",
      "25/250: import sys\n",
      "25/251:\n",
      "# establish a list to store our result\n",
      "results = []\n",
      "for page in all_pages:\n",
      "    # send a request\n",
      "    r = requests.get(page)\n",
      "    soup = BeautifulSoup(r.content, 'html.parser')\n",
      "    \n",
      "    # extract title and value of the html results:\n",
      "    k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "    v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "    k = [i.get_text() for i in k]\n",
      "    v = [i.get_text() for i in v]\n",
      "    \n",
      "    row = {k[i]: v[i] for i in range(len(k))} \n",
      "    # append result to our results\n",
      "    results.append(row)\n",
      "    \n",
      "    sys.sleep(uniform(0.1, 4))\n",
      "25/252:\n",
      "# establish a list to store our result\n",
      "results = []\n",
      "for page in all_pages:\n",
      "    # send a request\n",
      "    r = requests.get(page)\n",
      "    soup = BeautifulSoup(r.content, 'html.parser')\n",
      "    \n",
      "    # extract title and value of the html results:\n",
      "    k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "    v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "    k = [i.get_text() for i in k]\n",
      "    v = [i.get_text() for i in v]\n",
      "    \n",
      "    row = {k[i]: v[i] for i in range(len(k))} \n",
      "    # append result to our results\n",
      "    results.append(row)\n",
      "    \n",
      "    time.sleep(uniform(0.1, 4))\n",
      "25/253: results\n",
      "25/254: pd.DataFrame(results)\n",
      "25/255: # pd.DataFrame(results)\n",
      "25/256: soup\n",
      "25/257: pd.DataFrame(results)\n",
      "25/258: # pd.DataFrame(results)\n",
      "25/259: soup.findall('h2')\n",
      "25/260: soup.find_all('h2')\n",
      "25/261: soup.find_all('h3')\n",
      "25/262: soup.find_all('flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "25/263: soup.find_all(_class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "25/264: soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "25/265: soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx').get_text()\n",
      "25/266: soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx').get_text\n",
      "25/267:\n",
      "p = soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[p.get_text() for i in p]\n",
      "25/268:\n",
      "p = soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "#[p.get_text() for i in p]\n",
      "p\n",
      "25/269:\n",
      "p = soup.find_all('h3',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "#[p.get_text() for i in p]\n",
      "p\n",
      "25/270:\n",
      "p = soup.find_all('h2',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "#[p.get_text() for i in p]\n",
      "p\n",
      "25/271:\n",
      "p = soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "#[p.get_text() for i in p]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/272:\n",
      "p = soup.find_all(class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "#[p.get_text() for i in p]\n",
      "p\n",
      "25/273:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "#[p.get_text() for i in p]\n",
      "p\n",
      "25/274:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[p.get_text() for i in p]\n",
      "#p\n",
      "25/275:\n",
      "p = soup.find('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[p.get_text() for i in p]\n",
      "#p\n",
      "25/276:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[p.get_text() for i in p]\n",
      "#p\n",
      "25/277:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "# [p.get_text() for i in p]\n",
      "#p\n",
      "25/278:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "# [p.get_text() for i in p]\n",
      "#p\n",
      "p\n",
      "25/279:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "#p\n",
      "25/280:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "p\n",
      "25/281:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "25/282:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "p\n",
      "25/283:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "25/284: page\n",
      "25/285: print(page)\n",
      "25/286:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev.flexboxgrid__col-sm-3__28H0F.flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "25/287:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev.flexboxgrid__col-sm-3__28H0F.flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "25/288:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev.flexboxgrid__col-sm-3__28H0F.flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "25/289:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev.flexboxgrid__col-sm-3__28H0F.flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "\n",
      "p\n",
      "25/290:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "p\n",
      "25/291:\n",
      "p = soup.find_all('h3',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "p\n",
      "25/292:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#p\n",
      "p\n",
      "25/293:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "[i.get_text() for i in p]\n",
      "#pp\n",
      "25/294:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|xa0') for i in p]\n",
      "#pp\n",
      "25/295:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|xa0', '', i) for i in p]\n",
      "#pp\n",
      "25/296:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|xa0', '', str(i)) for i in p]\n",
      "#pp\n",
      "25/297:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|xa0', '', str(i)) for i in p]\n",
      "#pp\n",
      "price\n",
      "25/298:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|xa0', '', str(i)) for i in price]\n",
      "#pp\n",
      "price\n",
      "25/299:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|xa0', '', str(i)) for i in price]\n",
      "#pp\n",
      "price\n",
      "25/300:\n",
      "p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "price = [i.get_text() for i in p]\n",
      "price = [re.sub('Hinta|\\xa0', '', str(i)) for i in price]\n",
      "#pp\n",
      "price\n",
      "25/301: # pd.DataFrame(results)\n",
      "25/302:\n",
      "\n",
      "for page in tqdm(all_pages):\n",
      "    print(page)\n",
      "25/303:\n",
      "\n",
      "for page in tqdm(all_pages):\n",
      "    time.sleep(1)\n",
      "    print(page)\n",
      "25/304:\n",
      "# establish a list to store our result\n",
      "results = []\n",
      "for page in tqdm(all_pages):\n",
      "    # send a request\n",
      "    r = requests.get(page)\n",
      "    soup = BeautifulSoup(r.content, 'html.parser')\n",
      "    \n",
      "    # extract title and value of the html results: property characteristics\n",
      "    k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "    v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "    k = [i.get_text() for i in k]\n",
      "    v = [i.get_text() for i in v]\n",
      "    \n",
      "    # extract property price\n",
      "    p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "    price = [i.get_text() for i in p]\n",
      "    price = [re.sub('Hinta|\\xa0', '', str(i)) for i in price]\n",
      "\n",
      "    row = {k[i]: v[i] for i in range(len(k))} \n",
      "    row['price'] = price\n",
      "    d['mynewkey'] = 'mynewvalue'\n",
      "    # append result to our results\n",
      "    results.append(row)\n",
      "    \n",
      "    time.sleep(uniform(0.1, 4))\n",
      "25/305:\n",
      "# establish a list to store our result\n",
      "results = []\n",
      "for page in tqdm(all_pages):\n",
      "    # send a request\n",
      "    r = requests.get(page)\n",
      "    soup = BeautifulSoup(r.content, 'html.parser')\n",
      "    \n",
      "    # extract title and value of the html results: property characteristics\n",
      "    k = soup.find_all('div', class_=\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-4__3RH7g ItemHeader__itemHeader__32xAv\")\n",
      "    v = soup.find_all('div', class_=\"CompactInfoRow__infoRow__2hjs_ flexboxgrid__row__wfmuy\")\n",
      "    k = [i.get_text() for i in k]\n",
      "    v = [i.get_text() for i in v]\n",
      "    \n",
      "    # extract property price\n",
      "    p = soup.find_all('div',class_='flexboxgrid__col-xs-4__p2Lev flexboxgrid__col-sm-3__28H0F flexboxgrid__col-md-5__3SFMx')\n",
      "    price = [i.get_text() for i in p]\n",
      "    price = [re.sub('Hinta|\\xa0', '', str(i)) for i in price]\n",
      "    \n",
      "    # extract result to dictionary\n",
      "    row = {k[i]: v[i] for i in range(len(k))} \n",
      "    row['price'] = price\n",
      "    results.append(row)\n",
      "    \n",
      "    time.sleep(uniform(0.1, 4))\n",
      "25/306: pd.DataFrame(results)\n",
      "25/307: pd.DataFrame(results).filter(like='price')\n",
      "25/308: results\n",
      "25/309: pd.DataFrame(results).to_csv('../data/raw/listing_price.csv')\n",
      "25/310:\n",
      "# save to dataframe\n",
      "\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "25/311:\n",
      "# save to dataframe\n",
      "\n",
      "today = date.today().strftime(\"%d/%m/%Y\")\n",
      "\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "25/312:\n",
      "# save to dataframe\n",
      "from datetime import date\n",
      "today = date.today().strftime(\"%d/%m/%Y\")\n",
      "\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "25/313:\n",
      "# save to dataframe\n",
      "from datetime import date\n",
      "today = date.today().strftime(\"%d/%m/%Y\")\n",
      "\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "df\n",
      "25/314:\n",
      "# save to dataframe\n",
      "from datetime import date\n",
      "today = date.today().strftime(\"%d/%m/%Y\")\n",
      "\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "25/315:\n",
      "# save to dataframe\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "df.to_csv('../data/raw/listing_price.csv')\n",
      "25/316:\n",
      "# save to dataframe\n",
      "df = pd.DataFrame(results)\n",
      "df['date_scrape'] = today\n",
      "df.to_csv('../data/raw/listing_price.csv', index=False)\n",
      "25/317:\n",
      "import re\n",
      "import time\n",
      "import sys\n",
      "from random import uniform  \n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import requests\n",
      "\n",
      "from tqdm import tqdm\n",
      "\n",
      "from datetime import date\n",
      "\n",
      "\n",
      "today = date.today().strftime(\"%d/%m/%Y\")\n",
      "\n",
      "# finding the how many pages in the website so that we can build a loop to extract all hrefs\n",
      "base_url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu=2'\n",
      "page = requests.get(base_url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "page = soup.find_all('button', attrs={'data-react-toolbox':'button', \n",
      "                               'class':'theme__button__1YqFK theme__flat__13aFK theme__button__1YqFK theme__squared__17Uvn theme__neutral__1F1Jf Button__button__3K-jn Pagination__button__3H2wX'})\n",
      "\n",
      "page = [int(i.get_text()) for i in page]\n",
      "max_page = max(page) # this is our max page number\n",
      "25/318:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.extend(links_with_text)\n",
      "    \n",
      "# filter only relevant href and contact the domain names\n",
      "all_pages = list(set(['https://www.etuovi.com'+page for page in unit_pages if 'kohde' in page]))\n",
      "24/207: pd.read_csv('../data/raw/listing_price.csv')\n",
      "24/208: pd.read_csv('../data/raw/listing_price.csv').filter('Price')\n",
      "24/209: pd.read_csv('../data/raw/listing_price.csv').filter('price')\n",
      "24/210: pd.read_csv('../data/raw/listing_price.csv').filter('price')\n",
      "24/211: pd.read_csv('../data/raw/listing_price.csv')\n",
      "25/319: df.head()\n",
      "25/320: df.head().filter(like='price')\n",
      "25/321: df.filter(like='price')\n",
      "25/322: mydf = pd.read_csv('../data/raw/listing_price.csv')\n",
      "25/323: mydf.filter(like='price')\n",
      "24/212: pd.read_csv('../data/raw/listing_price.csv').filter(like='price')\n",
      "25/324: all_pages\n",
      "25/325: unit_pages\n",
      "25/326: set(unit_pages)\n",
      "25/327:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "max_page = 5\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = 'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={}.format(i)'\n",
      "    print(url)\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.extend(links_with_text)\n",
      "    \n",
      "# filter only relevant href and contact the domain names\n",
      "all_pages = list(set(['https://www.etuovi.com'+page for page in unit_pages if 'kohde' in page]))\n",
      "25/328:\n",
      "# find href in the each page so we can go to specific advertisement to crawl all the details.\n",
      "max_page = 5\n",
      "\n",
      "unit_pages =[] \n",
      "for i in tqdm(range(1, max_page)):\n",
      "    url = f'https://www.etuovi.com/myytavat-asunnot?haku=M1611624698&sivu={i}'\n",
      "    print(url)\n",
      "    page = requests.get(url)\n",
      "    soup = BeautifulSoup(page.content, 'html.parser')\n",
      "    links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
      "    unit_pages.extend(links_with_text)\n",
      "    \n",
      "# filter only relevant href and contact the domain names\n",
      "all_pages = list(set(['https://www.etuovi.com'+page for page in unit_pages if 'kohde' in page]))\n",
      "25/329: set(all_pages)\n",
      "25/330: len(all_pages)\n",
      "27/1:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "27/2:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "28/1:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "28/2: !pip install opencage\n",
      "28/3: !pip install geopandas\n",
      "28/4:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "28/5: df\n",
      "28/6: df.columns\n",
      "28/7: test = df.columns\n",
      "28/8:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].replace(col,'')\n",
      "28/9: df\n",
      "28/10:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "28/11: df\n",
      "28/12: df\n",
      "28/13: df.columns\n",
      "28/14: df.shape\n",
      "28/15: df.dropna(axis=0, how='all')\n",
      "28/16: df.dropna(axis=0, how='all').shape\n",
      "28/17: df.dropna(axis=0, how='any').shape\n",
      "28/18: df.dropna(axis=1, how='any').shape\n",
      "28/19: df.dropna(axis=1, how='all').shape\n",
      "28/20: df.columns\n",
      "28/21: df.heada()\n",
      "28/22: df.head()\n",
      "28/23:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "28/24:\n",
      "cols = {\n",
      "'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "}\n",
      "28/25: df.head()\n",
      "28/26: df.dropna(axis=1, how='any', threshold=0.5)\n",
      "28/27: df.dropna(axis=1, how='any', thresh=0.5)\n",
      "28/28: df.dropna(axis=1, how='any', thresh=0.5).shape\n",
      "28/29: df.dropna(axis=1, how='any', thresh=0.7).shape\n",
      "28/30: df.dropna(axis=1, how='all', thresh=0.7).shape\n",
      "28/31: df.dropna(axis=1, how='all', thresh=7).shape\n",
      "28/32: df.dropna(axis=1, how='all', thresh=10).shape\n",
      "28/33: df.dropna(axis=1, how='all', thresh=1000).shape\n",
      "28/34: df.dropna(axis=1, how='all', thresh=600).shape\n",
      "28/35:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',i\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "28/36:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "28/37: df.head()\n",
      "28/38:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "df['municipality'] = df['address'].map(lamda x: re.find(c, x) for c in cities)\n",
      "28/39:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "df['municipality'] = df['address'].map(lambda x: re.find(c, x) for c in cities)\n",
      "28/40:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "df['municipality'] = df['address'].map(lambda x: re.find(c, x)[0] for c in cities)\n",
      "28/41:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.find(c, x)[0] for c in cities)\n",
      "28/42:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.find('Espoo', x)[0])\n",
      "28/43:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', x)[0])\n",
      "28/44:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', x))\n",
      "28/45:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', x)[0] if not pd.isna(re.findall('Espoo', x)[0]) else 'A' )\n",
      "28/46: df['address'].unique()\n",
      "28/47:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', x) if not pd.isna(re.findall('Espoo', x)[0]) else 'A' )\n",
      "28/48:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', x)  else 'A' )\n",
      "28/49:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', x)   )\n",
      "28/50:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', str(x))   )\n",
      "28/51:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Espoo', str(x)) for c in cities  )\n",
      "28/52:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall(c, str(x)) for c in cities  )\n",
      "28/53:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall(c, str(x)) if c i cities )\n",
      "28/54:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall(c, str(x)) if c in cities )\n",
      "28/55:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall(c, str(x)) if c in cities)\n",
      "28/56:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall(c, str(x)) if c in cities else 'A')\n",
      "28/57:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall(c, str(x)) for c in cities)\n",
      "28/58:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Helsinki', str(x)))\n",
      "28/59:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.find('Helsinki', str(x)))\n",
      "28/60:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.search('Helsinki', str(x)))\n",
      "28/61:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "# df['municipality'] = \n",
      "df['address'].map(lambda x: re.findall('Helsinki', str(x)))\n",
      "28/62:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "re.findall(cities[2])\n",
      "28/63:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "re.findall(cities[2],a)\n",
      "28/64:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.findall(c, a) for c in cities]\n",
      "28/65:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.findall(c, a) for c in cities][0]\n",
      "28/66:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.findall(c, a) for c in cities]\n",
      "28/67:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.findall(c, a) for c in cities][3]\n",
      "28/68:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.findall(c, a) for c in cities][2]\n",
      "28/69:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.sub(f'{c}.*','{c}', a) for c in cities][2]\n",
      "28/70:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.sub(f'{c}.*',f'{c}', a) for c in cities][2]\n",
      "28/71:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.sub(f'{c}.*',f'{c}', a) for c in cities]\n",
      "28/72:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.sub(f'{c}.*',f'{c}', a) if c in cities]\n",
      "28/73:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.sub(f'{c}.*',f'{c}', a) if for in cities]\n",
      "28/74:\n",
      "a = 'Helsinki fsdcfsdf'\n",
      "[re.sub(f'{c}.*',f'{c}', a) for c in cities]\n",
      "28/75:\n",
      "cities = ['Espoo', 'Vantaa', 'Helsinki']\n",
      "df['address']\n",
      "28/76: df['address'].map(lambda x: x.split(x, '\\s')[0])\n",
      "28/77: df['address'].map(lambda x: x.split(str(x), '\\s')[0])\n",
      "28/78: df['address'].map(lambda x: x.split(str(x), '\\s'))\n",
      "28/79: df['address'].map(lambda x: str(x).split(str(x), '\\s'))\n",
      "28/80: df['address'].map(lambda x: str(x).split('\\s'))\n",
      "28/81: df['address'].map(lambda x: str(x).split('\\s')[0])\n",
      "28/82: df['address'].map(lambda x: str(x).split(' ')[0])\n",
      "28/83: df['address'].map(lambda x: s.split()[0])\n",
      "28/84: df['address'].map(lambda s: s.split()[0])\n",
      "28/85: df['address'].map(lambda s: str(s).split()[0])\n",
      "28/86:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "28/87: df.head()\n",
      "28/88: df['municipality'].plot(kind='bar')\n",
      "28/89:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import maplotlib\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "28/90:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "28/91: ! pip install matplotlib\n",
      "28/92:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "28/93: df['municipality'].plot(kind='bar')\n",
      "28/94: df['municipality'].value_counts().plot(kind='bar')\n",
      "28/95: df['municipality'].isnull().mean()\n",
      "28/96:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['address'].map(lambda s: re.findall('\\d{5}'))\n",
      "28/97:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['address'].map(lambda s: re.findall('\\d{5}',str(s)))\n",
      "28/98:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0])\n",
      "28/99:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}',str(s))[0] ) )\n",
      "28/100:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}',str(s))[0] else None )\n",
      "28/101:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}', str(s)) else None )\n",
      "28/102:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}', str(s)) )\n",
      "28/103:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}', str(s))\n",
      "28/104:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}', str(s)) else None)\n",
      "28/105:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}', str(s)) else None)\n",
      "28/106:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}', str(s)) else None)\n",
      "28/107:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not re.findall('\\d{5}',str(s))[0] )\n",
      "28/108:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not re.findall('\\d{5}',str(s))[0] else None)\n",
      "28/109:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}',str(s))[0]) else None)\n",
      "28/110:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s))[0] if not pd.isna(re.findall('\\d{5}',str(s))) else None)\n",
      "28/111:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "28/112: df['postcode'].isnull().mean()\n",
      "28/113: df['postcode']\n",
      "28/114: df['postcode'][0]\n",
      "28/115: df['postcode']\n",
      "28/116: df['postcode'].map(lambda x: x[0] )\n",
      "28/117: df['postcode'].map(lambda x: x[0] if len(x)>0)\n",
      "28/118: df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "28/119:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "28/120: df.head()\n",
      "28/121: df.type.value_counts()\n",
      "28/122: df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "28/123: df['property_type'].value_count().plot()\n",
      "28/124: df['property_type'].value_count().plot(kind='bar')\n",
      "28/125: df['property_type'].value_counts().plot(kind='bar')\n",
      "28/126: df.head()\n",
      "28/127: df.form_of_ownership.value_counts()\n",
      "28/128: df.form_of_ownership[df.form_of_ownership=='Asumisoikeusasunto     ']\n",
      "28/129: df.form_of_ownership[df.form_of_ownership=='Asumisoikeusasunto']\n",
      "28/130: df.form_of_ownership[df.form_of_ownership=='Asumisoikeusasunto'].price_m2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/131: df.form_of_ownership[df.form_of_ownership=='Asumisoikeusasunto']\n",
      "28/132: df[df.form_of_ownership=='Asumisoikeusasunto']\n",
      "28/133: df[df.form_of_ownership=='Asumisoikeusasunto'].price_m2\n",
      "28/134:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df[df.form_of_ownership=='Omistusasunto']\n",
      "28/135:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df[df.form_of_ownership=='Omistusasunto'].shape\n",
      "28/136:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "28/137: df.head()\n",
      "28/138: df.Huoneita.price_m2\n",
      "28/139: df.Huoneita.value_counts()\n",
      "28/140: df['number_of_rooms'] = df['rooms'].map(lambda x: re.sub('\\dh','', x))\n",
      "28/141: df['number_of_rooms'] = df['rooms'].map(lambda x: re.sub('\\dh','', str(x)))\n",
      "28/142: df['number_of_rooms'].value_counts()\n",
      "28/143: df['Huonetta'].value_counts()\n",
      "28/144:\n",
      "df['property_type'].value_counts().plot(kind='bar')\n",
      "\n",
      "df.head()\n",
      "28/145: df['Huoneita'].value_counts()\n",
      "28/146:\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': NA\n",
      "              \n",
      "              \n",
      "              \n",
      "    \n",
      "}\n",
      "28/147:\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None\n",
      "              \n",
      "              \n",
      "              \n",
      "    \n",
      "}\n",
      "28/148: df['Huoneita'].replace(rooms_type)\n",
      "28/149: df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "28/150: df['number_of_rooms'].value_count().plot()\n",
      "28/151: df['number_of_rooms'].value_counts).plot()\n",
      "28/152: df['number_of_rooms'].value_counts()).plot()\n",
      "28/153: df['number_of_rooms'].value_counts().plot()\n",
      "28/154: df['number_of_rooms'].value_counts().plot(kind='bar')\n",
      "28/155: df['number_of_rooms'].value_counts().plot(kind='bar');\n",
      "28/156: df.head()\n",
      "28/157: df.filter(like='price')\n",
      "28/158:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].dtype\n",
      "28/159:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].mpa(lambda: x[0])\n",
      "28/160:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: x[0])\n",
      "28/161:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: x[1])\n",
      "28/162:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.sub('\\d{3,}')\n",
      "28/163:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.sub('\\d{3,}', x)\n",
      "28/164:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.sub('\\d{3,}', x) )\n",
      "28/165:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.sub('\\d{3,}', '', x) )\n",
      "28/166:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{3,}', '', x) )\n",
      "28/167:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{3,}',  x) )\n",
      "28/168:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{3,}',  x)[0] )\n",
      "28/169:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x)[0] if not pd.isna(x) )\n",
      "28/170:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x)[0] if not pd.isna(x) else None )\n",
      "28/171:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x)[0] if not pd.isna(re.findall('\\d{4,}', x)[0]) else None )\n",
      "28/172:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x)[0] if not pd.isna(re.findall('\\d{4,}', x)) else None )\n",
      "28/173:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x)[0] )\n",
      "28/174:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split())\n",
      "28/175:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x) )\n",
      "28/176:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) = \n",
      "df['price'] = df['price'].map(lambda x: x[0] if not pd.isna(x))\n",
      "28/177:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if not pd.isna(x))\n",
      "28/178:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if not pd.isna(x) else None)\n",
      "28/179:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if not len(x) >0 else None)\n",
      "28/180:\n",
      "df.filter(like='price')\n",
      "df\n",
      "28/181:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split())\n",
      "28/182:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if not len(x) >0 else None)\n",
      "28/183:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split())\n",
      "28/184:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "# df['price'] = \n",
      "df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "# df['price'] = df['price'].map(lambda x: x[0] if not len(x) >0 else None)\n",
      "28/185:\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "# df['price'] = df['price'].map(lambda x: x[0] if not len(x) >0 else None)\n",
      "28/186: df['price'].map(lambda x: x[0] if not len(x) >0 else None)\n",
      "28/187: df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "28/188:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split())\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "28/189: df.head()\n",
      "28/190:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "28/191: df.head()\n",
      "28/192: df.filter(like='price')\n",
      "28/193: df.filter(like='area')\n",
      "29/1:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "29/2: df.filter(like='area')\n",
      "29/3:\n",
      "x = 'AAAANN'\n",
      "x.replace('A', 'B')\n",
      "29/4:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace(' m', ''))\n",
      "29/5: df.filter(like='area')\n",
      "29/6:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace(' m', ''), axis=1)\n",
      "29/7: df.filter(like='area')\n",
      "29/8: df.filter(like='area')\n",
      "29/9:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=1)\n",
      "29/10: df.filter(like='area')\n",
      "29/11:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=0)\n",
      "29/12: df.filter(like='area')\n",
      "29/13:\n",
      "x = '107 m'\n",
      "x.replace('A', 'm')\n",
      "29/14:\n",
      "x = '107 m'\n",
      "x.replace('A', 'm')\n",
      "29/15:\n",
      "x = '107 m'\n",
      "x.replace('m', '')\n",
      "29/16:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=1\n",
      "                                                                           )\n",
      "29/17: df.filter(like='area')\n",
      "29/18:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].map(lambda x: x.replace('m', ''))\n",
      "29/19:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "#df[['living_area', 'total_area']] = df[['living_area', 'total_area']].map(lambda x: x.replace('m', ''))\n",
      "29/20:\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''))\n",
      "\n",
      "df.filter(like='area')\n",
      "29/21:\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=1)\n",
      "\n",
      "df.filter(like='area')\n",
      "29/22:\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=1)\n",
      "df['living_area'] = df['living_area'].map(lambda x: x.replace('m', ''))\n",
      "df['living_area'] = df[['living_area', \n",
      "df.filter(like='area')\n",
      "29/23:\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=1)\n",
      "df['living_area'] = df['living_area'].map(lambda x: x.replace('m', ''))\n",
      "#df['living_area'] = df[['living_area', \n",
      "df.filter(like='area')\n",
      "29/24:\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: x.replace('m', ''), axis=1)\n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace('m', ''))\n",
      "#df['living_area'] = df[['living_area', \n",
      "df.filter(like='area')\n",
      "29/25:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "#df[['living_area', 'total_area']] = df[['living_area', 'total_area']].map(lambda x: x.replace('m', ''))\n",
      "29/26:\n",
      "df[['living_area', 'total_area']] = df[['living_area', 'total_area']].apply(lambda x: str(x).replace('m', ''), axis=1)\n",
      "#df['living_area'] = df['living_area'].map(lambda x: str(x).replace('m', ''))\n",
      "#df['living_area'] = df[['living_area', \n",
      "df.filter(like='area')\n",
      "29/27:\n",
      "\n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace('m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace('m', ''))\n",
      " \n",
      "df.filter(like='area')\n",
      "29/28:\n",
      "\n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      " \n",
      "df.filter(like='area')\n",
      "29/29:\n",
      "x = '107 m'\n",
      "x.replace('m', '')\n",
      "29/30:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "29/31:\n",
      "\n",
      "\n",
      " \n",
      "df.filter(like='area')\n",
      "29/32: df\n",
      "29/33:\n",
      "\n",
      "\n",
      " \n",
      "df.land_ownership\n",
      "29/34:\n",
      "\n",
      "\n",
      " \n",
      "df.land_ownership.value_counts()\n",
      "29/35:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2 \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "# turn them into numeric values\n",
      "df['living_area'] = df['living_area'].map(lambda x: np.float(str(x).replace(',', '.')) if not pd.isna() else None )\n",
      "29/36:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2 \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "# turn them into numeric values\n",
      "df['living_area'] = df['living_area'].map(lambda x: np.float(str(x).replace(',', '.')) if not pd.isna(x) else None )\n",
      "29/37:\n",
      "\n",
      "\n",
      " \n",
      "df.filter(like='area')\n",
      "29/38:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2 \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "# turn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: np.float(str(x).replace(',', '.')) if not pd.isna(x) else None )\n",
      "29/39: df['total_area'].nunique()\n",
      "29/40: df['total_area'].unique()\n",
      "29/41:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2 \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "# turn them into numeric values\n",
      "# for col in ['living_area', 'total_area']:\n",
      "#     df[col] = df[col].map(lambda x: np.float(str(x).replace(',', '.')) if not (pd.isna(x) and isinstance(x, str)) else None )\n",
      "29/42:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2 \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "# turn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: np.float(str(x).replace(',', '.')) if not (pd.isna(x) and isinstance(x, str)) else None )\n",
      "29/43:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2 \n",
      "df['living_area'] = df['living_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "df['total_area'] = df['total_area'].map(lambda x: str(x).replace(' m', ''))\n",
      "# turn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "29/44:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "29/45: df.sauna.unique()\n",
      "29/46: df.Sauna.unique()\n",
      "29/47:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)\n",
      "29/48: df.private_sauna.unique()\n",
      "29/49: df.private_sauna.value_counts()\n",
      "29/50: df.head()\n",
      "29/51:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)\n",
      "29/52: df.filter(like='yeat')\n",
      "29/53: df.filter(like='year')\n",
      "29/54: df.filter(like='year')\n",
      "29/55: df.head()\n",
      "29/56:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)\n",
      "29/57: df.filter(like='Year')\n",
      "29/58: df.filter(like='year')\n",
      "29/59:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', x))\n",
      "29/60:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', str(x))[0])\n",
      "29/61:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', str(x))[0] if not pd.isna(x))\n",
      "29/62:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', str(x))[0] if not pd.isna(x) )\n",
      "29/63:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', str(x))[0]  )\n",
      "29/64:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', str(x))[0] if not pd.isna(x) )\n",
      "29/65:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.search('\\d{4}', str(x))[0] if not pd.isna(x)else x )\n",
      "29/66: df['construction_year'].unique()\n",
      "29/67:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.sub('\\d{4}(.*)','\\d{4}', str(x)) if not pd.isna(x)else x )\n",
      "29/68:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.sub('[0-9]{4}(.*)','[0-9]{4}', str(x)) if not pd.isna(x)else x )\n",
      "29/69:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "# df['construction_year'].map(lambda x: re.sub('[0-9]{4}(.*)','[0-9]{4}', str(x)) if not pd.isna(x)else x )\n",
      "29/70: df['construction_year'].unique()\n",
      "29/71:\n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('\\d{4}(.*)?')\n",
      "29/72:\n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('\\d{4}(.*)?', '\\d{4}', x)\n",
      "29/73:\n",
      "import regex as re i\n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('\\d{4}(.*)?', '\\d{4}', x)\n",
      "29/74:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('\\d{4}(.*)?', '\\d{4}', x)\n",
      "29/75: ! pip install regex\n",
      "29/76:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('\\d{4}(.*)?', '\\d{4}', x)\n",
      "29/77:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'\\d{4}(.*)?', r'\\d{4}', x)\n",
      "29/78:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'\\\\\\d{4}(.*)?', r'\\\\\\d{4}', x)\n",
      "29/79:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'\\\\\\d{4}(.*)', r'\\\\\\d{4}', x)\n",
      "29/80:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.gsub(r'\\\\\\d{4}(.*)', r'\\\\\\d{4}', x)\n",
      "29/81:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'\\\\\\d{4}(.*)', r'\\\\\\d{4}', x)\n",
      "29/82:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'\\\\\\d{4}(.*)', r'00', x)\n",
      "29/83:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'\\\\\\d{4}(.*)', '', x)\n",
      "29/84:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\\\\\d{4})(.*)', '', x)\n",
      "29/85:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('2020', '', x)\n",
      "29/86:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('(\\d+)' , '', x\")\n",
      "29/87:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('(\\d+)' , '', x)\n",
      "29/88:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('(\\d{4})' , '', x)\n",
      "29/89:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('(\\d{4})(.*?)' , '', x)\n",
      "29/90:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub('(\\d{4})(.*)?' , '', x)\n",
      "29/91:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.sub('(\\d{4})(.*)?' , '(\\d{4})', x) if not pd.isna(x)else x )\n",
      "29/92:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?', r'(\\d{4})', x) if not pd.isna(x) else x )\n",
      "29/93:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?', r'(\\d{4})', x)\n",
      "29/94:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?', '', x)\n",
      "29/95:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?', '00', x)\n",
      "29/96:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?', 1, x)\n",
      "29/97:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?',r'(\\d{4}) , x)\n",
      "29/98:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?',r'(\\d{4})' , x)\n",
      "29/99:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?', (1) , x)\n",
      "29/100:\n",
      "import regex as re \n",
      "x = '2020 (Uudiskohde)'\n",
      "re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x)\n",
      "29/101:\n",
      "import regex as re \n",
      "x = '2020'\n",
      "re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x)\n",
      "29/102:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "29/103:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "29/104: df['construction_year'].unique()\n",
      "29/105:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(int)\n",
      "29/106:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "29/107: df['construction_year'].unique()\n",
      "29/108: df.parking_type.unique()\n",
      "29/109: f.head()\n",
      "29/110: df.head()\n",
      "29/111: df.price\n",
      "29/112: df['price_m2_compute'] = df['price'] / df['livjng_area']\n",
      "29/113: df['price_m2_compute'] = df['price'] / df['living_area']\n",
      "29/114: df['price_m2_compute'] = np.float(df['price']) / df['living_area']\n",
      "29/115: df['price'].dtype\n",
      "29/116:\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "29/117: df['price_m2_compute'].plot()\n",
      "29/118: df['price_m2_compute'].hist()\n",
      "29/119: df['price_m2_compute'].hist(30)\n",
      "29/120: df['price_m2_compute'].hist(bins=50)\n",
      "29/121:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.kdeplot(df['price_m2_compute'], )\n",
      "29/122: ! pip install seaborn\n",
      "29/123:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.kdeplot(df['price_m2_compute'], )\n",
      "29/124:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.hist(df['price_m2_compute'],)\n",
      "29/125:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.distplot(df['price_m2_compute'],)\n",
      "29/126:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.distplot(df['price_m2_compute'],hue='property_type')\n",
      "29/127:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.distplot(df['price_m2_compute'],color='property_type')\n",
      "29/128:\n",
      "import seaborn as sns\n",
      "\n",
      "sns.distplot(df['price_m2_compute'],color='b')\n",
      "29/129:\n",
      "import seaborn as sns\n",
      "sns.displot(\n",
      "    df, x=\"price_m2_compute\", col=\"property_type\", \n",
      "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
      ")\n",
      "29/130: df.filter(like='price')\n",
      "29/131: df.head()\n",
      "29/132:\n",
      "df.head()\n",
      "df.upcoming_renovations\n",
      "29/133:\n",
      "df.head()\n",
      "df.upcoming_renovations.unique()\n",
      "29/134: df.address\n",
      "29/135: df.additional_charge\n",
      "29/136: df.company_compensation\n",
      "29/137: df.Hissi\n",
      "29/138: df.elevator\n",
      "29/139: df.elavator\n",
      "29/140: df.elavator.unique()\n",
      "29/141:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Tyydyttv':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "\n",
      "# elavator\n",
      "df['elavator'] = np.where(df['Sauna'].isin(['Taloyhtiss on hissi']), True, False)\n",
      "29/142: df\n",
      "29/143: df['source'] = 'https://www.etuovi.com/kohde/' + df['Kohdenumero'] + '?haku=M1618619882'\n",
      "29/144: df['source'].iloc[10]\n",
      "29/145: df['condition'].unique()\n",
      "29/146: df['condition'].unique()\n",
      "29/147: df['condition']\n",
      "29/148: df\n",
      "29/149: df['Tyydyttv']\n",
      "29/150: df['condition']\n",
      "29/151: df\n",
      "29/152:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Asunnon kunto':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "\n",
      "# elavator\n",
      "df['elavator'] = np.where(df['Sauna'].isin(['Taloyhtiss on hissi']), True, False)\n",
      "\n",
      "# source of the advertisement\n",
      "df['source'] = 'https://www.etuovi.com/kohde/' + df['Kohdenumero'] + '?haku=M1618619882'\n",
      "29/153: df.condition\n",
      "29/154: df.condition.unique()\n",
      "29/155:\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying'\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             nan: 'Not classified',  \n",
      "}\n",
      "29/156:\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             nan: 'Not classified',  \n",
      "}\n",
      "29/157:\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             np.nan: 'Not classified',  \n",
      "}\n",
      "29/158:\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             np.nan: 'Not classified',  \n",
      "}\n",
      "\n",
      "df.condition = df.condition.replace(condition)\n",
      "29/159: df.condition.unique()\n",
      "29/160: df.property_type.value_counts().plot(kind='bar')\n",
      "29/161: df[df.price_m2 > 10000]\n",
      "29/162: df[df.price_m2_compute > 10000]\n",
      "29/163: df[df.price_m2_compute > 12000]\n",
      "29/164:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Asunnon kunto':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "\n",
      "# elavator\n",
      "df['elavator'] = np.where(df['Sauna'].isin(['Taloyhtiss on hissi']), True, False)\n",
      "\n",
      "# source of the advertisement\n",
      "df['source'] = 'https://www.etuovi.com/kohde/' + df['Kohdenumero'] + '?haku=M1618619882'\n",
      "\n",
      "# translate condition to English\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             np.nan: 'Not classified',  \n",
      "}\n",
      "df.condition = df.condition.replace(condition)\n",
      "\n",
      "# save file\n",
      "\n",
      "df.to_csv('../preprocessing/listing_price.csv', sep= ';')\n",
      "29/165:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Asunnon kunto':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "\n",
      "# elavator\n",
      "df['elavator'] = np.where(df['Sauna'].isin(['Taloyhtiss on hissi']), True, False)\n",
      "\n",
      "# source of the advertisement\n",
      "df['source'] = 'https://www.etuovi.com/kohde/' + df['Kohdenumero'] + '?haku=M1618619882'\n",
      "\n",
      "# translate condition to English\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             np.nan: 'Not classified',  \n",
      "}\n",
      "df.condition = df.condition.replace(condition)\n",
      "\n",
      "# save file\n",
      "\n",
      "df.to_csv('../preprocessing/listing_price.csv', sep= ';', index= False)\n",
      "29/166:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Asunnon kunto':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "\n",
      "# elavator\n",
      "df['elavator'] = np.where(df['Sauna'].isin(['Taloyhtiss on hissi']), True, False)\n",
      "\n",
      "# source of the advertisement\n",
      "df['source'] = 'https://www.etuovi.com/kohde/' + df['Kohdenumero'] + '?haku=M1618619882'\n",
      "\n",
      "# translate condition to English\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             np.nan: 'Not classified',  \n",
      "}\n",
      "df.condition = df.condition.replace(condition)\n",
      "\n",
      "# save file\n",
      "\n",
      "df.to_csv('../data/processed/listing_price.csv', sep= ';', index= False)\n",
      "29/167:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "import matplotlib \n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "pd.set_option('display.max_columns', 150)\n",
      "\n",
      "\n",
      "df = pd.read_csv('../../data/raw/listing_price.csv')\n",
      "\n",
      "# remove col name from row values:\n",
      "for col in df.columns:\n",
      "    df[col] = df[col].str.replace(col,'')\n",
      "    \n",
      "# change name of the df\n",
      "cols = {\n",
      "    'Sijainti' : 'address',\n",
      "    'Tyyppi': 'type',\n",
      "    'Omistusmuoto': 'form_of_ownership',\n",
      "    'Huoneistoselitelm':'rooms',\n",
      "    'Asuintilojen pinta-ala': 'living_area',\n",
      "    'Kerrokset':'floors',\n",
      "    'Rakennusvuosi':'construction_year',\n",
      "    'Velaton hinta': 'debt_free_price',\n",
      "    'Myyntihinta': 'selling_price',\n",
      "    'Velkaosuus': 'debt_ratio',\n",
      "    'Nelihinta': 'price_m2',\n",
      "    'Yhtivastike':'company_compensation',\n",
      "    'Vesimaksu': 'water_charge',\n",
      "    'Listiedot maksuista': 'additional_charge',\n",
      "    'Parveke': 'balcony',\n",
      "    'Hissi': 'elavator',\n",
      "    'Lmmitysjrjestelm': 'heating_system',\n",
      "    'Taloyhtin kuuluu': 'building_facilities',\n",
      "    'Taloyhtin autopaikat': 'parking_type',\n",
      "    'Energialuokka':'energy_class',\n",
      "    'Tontin omistus': 'land_ownership',\n",
      "    'Kokonaispinta-ala':'total_area',\n",
      "    'Vapautuminen':'released_year',\n",
      "    'Asuntoon kuuluu': 'apartment_includes',\n",
      "    'Asunnon kunto':'condition',\n",
      "    'Lmmitysjrjestelmn kuvaus':'heating_system_type',\n",
      "    'Rakennus- ja pintamateriaalit':'building_surface_materials',\n",
      "    'Keittin kuvaus':'kitchen_description',\n",
      "    'Kylpyhuoneen kuvaus': 'bathroom_description',\n",
      "    'Olohuoneen kuvaus':'living_room_description',\n",
      "    'Kattotyyppi':'roof_type',\n",
      "    'Taloyhtin nimi':'housing_company_name',\n",
      "    'Tehdyt remontit':'rennovations_made',\n",
      "    'Tulevat remontit': 'upcoming_renovations',\n",
      "    'Tontin koko':'building_ground',\n",
      "}\n",
      "\n",
      "df = df.rename(columns=cols)\n",
      "\n",
      "# filter form of ownership == Omistusasunto: owning         \n",
      "df = df[df.form_of_ownership=='Omistusasunto']\n",
      "\n",
      "# extract municipality\n",
      "df['municipality'] = df['address'].map(lambda s: str(s).split()[0])\n",
      "\n",
      "# extract postcode\n",
      "df['postcode'] = df['address'].map(lambda s: re.findall('\\d{5}',str(s)) )\n",
      "df['postcode'] = df['postcode'].map(lambda x: x[0] if len(x)>0 else None)\n",
      "\n",
      "df['property_type'] = df.type.map(lambda s: str(s).split()[0])\n",
      "\n",
      "# number of rooms\n",
      "rooms_type = {'3 huonetta': 3,\n",
      "              'Kaksio': 2,\n",
      "              '4 huonetta': 4,\n",
      "              'Yksi': 1,\n",
      "              '5 huonetta': 5,\n",
      "              'Yli 5 huonetta':'5+',\n",
      "              'Ei tiedossa': None             \n",
      "}\n",
      "\n",
      "df['number_of_rooms'] = df['Huoneita'].replace(rooms_type)\n",
      "\n",
      "df['price'] = df['price'].map(lambda x: re.findall('\\d{4,}', x) ) \n",
      "df['price'] = df['price'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "\n",
      "# clean the area colummns: remove m2, replace ',' with ',', and then urn them into numeric values\n",
      "for col in ['living_area', 'total_area']:\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(' m', ''))\n",
      "    df[col] = df[col].map(lambda x: str(x).replace(',', '.'))\n",
      "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "\n",
      "# check if the apartment has private sauna:\n",
      "sauna = ['Asunnossa on saunaTaloyhtiss on sauna', 'Asunnossa on sauna']\n",
      "df['private_sauna'] = np.where(df['Sauna'].isin(sauna), True, False)    \n",
      "\n",
      "# construction year\n",
      "df['construction_year'] = df['construction_year'].map(lambda x: re.sub(r'(\\d{4})(.*)?',  r\"\\1\" , x) if not pd.isna(x) else x )\n",
      "df['construction_year'] = df['construction_year'].astype(float)\n",
      "\n",
      "df['price'] = df['price'].astype(float)\n",
      "df['price_m2_compute'] = np.round(df['price']) / df['living_area']\n",
      "\n",
      "# elavator\n",
      "df['elavator'] = np.where(df['Sauna'].isin(['Taloyhtiss on hissi']), True, False)\n",
      "\n",
      "# source of the advertisement\n",
      "df['source'] = 'https://www.etuovi.com/kohde/' + df['Kohdenumero'] + '?haku=M1618619882'\n",
      "\n",
      "# translate condition to English\n",
      "condition = { 'Tyydyttv' : 'Satisfying',\n",
      "             'Vlttv': 'Satisfying',\n",
      "             'Hyv': 'Good',\n",
      "             'Ei luokiteltu' : 'Not classified',\n",
      "             np.nan: 'Not classified',  \n",
      "}\n",
      "df.condition = df.condition.replace(condition)\n",
      "\n",
      "# save file\n",
      "\n",
      "df.to_csv('../../data/processed/listing_price.csv', sep= ';', index= False)\n",
      "   1:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_json('../data/raw/price.jl', lines=True,orient='records').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "   2: ! pip install geopandas\n",
      "33/1:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_json('../data/raw/price.jl', lines=True,orient='records').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "33/2: ! pip install geopandas\n",
      "33/3:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_json('../../data/raw/transaction_price.csv', lines=True,orient='records').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "33/4:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_json('../../data/raw/transaction_price.csv', lines=True,orient='records').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "33/5:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_csv('../../data/raw/transaction_price.csv', lines=True,orient='records').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "33/6:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_csv('../../data/raw/transaction_price.csv', sep = ';').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "33/7:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_csv('../../data/raw/transaction_price.csv', sep = ',').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "33/8:\n",
      "import json\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "#import geopandas as gpd\n",
      "import json\n",
      "import re\n",
      "import os\n",
      "\n",
      "from tqdm.notebook import tqdm\n",
      "from opencage.geocoder import OpenCageGeocode\n",
      "\n",
      "# ============================================\n",
      "# clean tranaction price df\n",
      "# ============================================\n",
      "def clean_transaction_price():\n",
      "    # load raw data:\n",
      "    df = pd.read_csv('../../data/raw/transaction_price.csv', sep = ',').drop_duplicates()\n",
      "    df = df.loc[~df.district.isnull()]\n",
      "    print(f'Orignal df transaction price: {df.shape}')\n",
      "    \n",
      "    # clean district name:\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
      "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
      "    df['district'] = df['district'].str.title()\n",
      "    \n",
      "    # number of rooms\n",
      "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
      "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
      "    \n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # property type\n",
      "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
      "                                                  'ok':'single-family house'})\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    return df\n",
      "    \n",
      "def geocode_address(df):\n",
      "    key = os.getenv('opencage_api')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "    postcode_dict = {}\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:            \n",
      "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "\n",
      "            \n",
      "    return postcode_dict    \n",
      "\n",
      "def merge_district(postcode_dict, df):\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                         \n",
      "    df = df.merge(df_postcode, on='district')\n",
      "            \n",
      "    return  df\n",
      "\n",
      "def geocode_address(df):\n",
      "    key = os.getenv('OPENCAGE_API_KEY')\n",
      "    geocoder = OpenCageGeocode(key)\n",
      "\n",
      "    postcode_dict = {}\n",
      "    postcode_null = []\n",
      "    district_geocode = df['district'].unique() # find list of unique postcode\n",
      "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
      "\n",
      "    for i in range(0, len(district_geocode)):\n",
      "        result= geocoder.geocode(district_geocode[i])\n",
      "        if len(result) > 1:\n",
      "            try:\n",
      "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
      "            except :\n",
      "                print(district_geocode[i])\n",
      "                postcode_null.append(district_geocode[i])\n",
      "        else:       \n",
      "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
      "      \n",
      "    return postcode_dict, postcode_null    \n",
      "\n",
      "\n",
      "def merge_district(postcode_dict, df):  \n",
      "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
      "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
      "    df_postcode.columns= ['district', 'postcode']\n",
      "    \n",
      "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
      "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
      "                                                          \n",
      "    df= df.merge(df_postcode, on='district')\n",
      "    print('Geocode postcode for df transaction price: done')\n",
      "            \n",
      "    return  df\n",
      " \n",
      "def process_transaction_df():\n",
      "    df = clean_transaction_price()\n",
      "    postcode_geo, postcode_null = geocode_address(df) \n",
      "    df = merge_district(postcode_geo, df)\n",
      "    \n",
      "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
      "    print('==== Save df transaction price: done ====')\n",
      "       \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# clean asking price df\n",
      "# ============================================\n",
      "\n",
      "def clean_df_listing():\n",
      "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
      "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
      "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
      "\n",
      "    # clean municipality\n",
      "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
      "    # number_of_room\n",
      "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
      "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
      "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
      "\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
      "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
      "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
      "    \n",
      "    # maitenance cost per sqm\n",
      "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
      "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
      "    \n",
      "    # filter potential wrong values\n",
      "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
      "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
      "                                                           # property sold with >20k/m2\n",
      "    # divide propery into 2 groups: house and apartment:\n",
      "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
      "    \n",
      "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
      "    print('==== Save df asking price: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "# ============================================\n",
      "# clean rent df\n",
      "# ============================================\n",
      "\n",
      "def load_rent():\n",
      "    # load file\n",
      "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
      "    \n",
      "    # clean columns\n",
      "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
      "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
      "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
      "    \n",
      "    # change dtype of rent columns\n",
      "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
      "    \n",
      "    # drop unneeded columns:\n",
      "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
      "\n",
      "    df.to_csv('../data/processed/rent.csv', index=False)\n",
      "    print('==== Save df rent: done ====')\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# merge df_rent, df_price and df_listing\n",
      "# ============================================\n",
      "\n",
      "def caculate_yield(x):\n",
      "    if x['new']:\n",
      "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    else:\n",
      "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
      "    \n",
      "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
      "    \n",
      "    return x['net_yield']\n",
      "\n",
      "def merge_df(df_rent, df_listing, df_price):\n",
      "    # correct format of postcode:\n",
      "    for df in [df_rent, df_listing, df_price]:\n",
      "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
      "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
      "        if 'number_of_room_cat' in df.columns:\n",
      "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
      "            \n",
      "    # merge price and listing\n",
      "\n",
      "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['price_m2'].mean().reset_index()\n",
      "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
      "                ['asking_price_m2'].mean().reset_index()\n",
      "    \n",
      "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
      "                      how='left').drop_duplicates()\n",
      "    \n",
      "    # merge df listing and df rent\n",
      "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
      "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
      "   \n",
      "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
      "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
      "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
      "    \n",
      "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
      "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
      "   \n",
      "    print('==== Save df yield and price: done ====')\n",
      "    \n",
      "    \n",
      "    return df_listing_price, df_yield\n",
      "        \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print('Start')\n",
      "    # df_rent = load_rent()\n",
      "    df_price = process_transaction_df()\n",
      "    # df_listing = clean_df_listing()\n",
      "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n",
      "   3: %history -g\n"
     ]
    }
   ],
   "source": [
    "%history -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g -f etuovi_clean-checkpoint.ipynb -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
