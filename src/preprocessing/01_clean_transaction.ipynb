{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'lines'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9de3a49e4d13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# df_rent = load_rent()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[0mdf_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_transaction_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;31m# df_listing = clean_df_listing()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;31m# df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9de3a49e4d13>\u001b[0m in \u001b[0;36mprocess_transaction_df\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_transaction_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_transaction_price\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[0mpostcode_geo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcode_null\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeocode_address\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_district\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpostcode_geo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9de3a49e4d13>\u001b[0m in \u001b[0;36mclean_transaction_price\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_transaction_price\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# load raw data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../data/raw/transaction_price.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Orignal df transaction price: {df.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'lines'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "# ============================================\n",
    "# clean tranaction price df\n",
    "# ============================================\n",
    "def clean_transaction_price():\n",
    "    # load raw data:\n",
    "    df = pd.read_csv('../../data/raw/transaction_price.csv', lines=True,orient='records').drop_duplicates()\n",
    "    df = df.loc[~df.district.isnull()]\n",
    "    print(f'Orignal df transaction price: {df.shape}')\n",
    "    \n",
    "    # clean district name:\n",
    "    df['district'] = df['district'].map(lambda x: re.sub('/', '-',str(x)) )\n",
    "    df['district'] = df['district'].map(lambda x: re.sub(',', '-',str(x)) )\n",
    "    df['district'] = df['district'].map(lambda x: re.sub('\\s', '',str(x)) )\n",
    "    df['district'] = df['district'].str.title()\n",
    "    \n",
    "    # number of rooms\n",
    "    df['apartment_type'] = df['apartment_type'].str.lower()\n",
    "    df['number_of_room'] = df['apartment_type'].map(lambda x: x[:1] if not pd.isna(x) else None)\n",
    "    df['number_of_room'] = pd.to_numeric(df['number_of_room'] , errors='coerce')\n",
    "    \n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
    "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
    "    \n",
    "    # property type\n",
    "    df['property_type']= df['property_type'].replace({'kt':'apartment', 'rt':'row house', \\\n",
    "                                                  'ok':'single-family house'})\n",
    "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def geocode_address(df):\n",
    "    key = os.getenv('opencage_api')\n",
    "    geocoder = OpenCageGeocode(key)\n",
    "    postcode_dict = {}\n",
    "    district_geocode = df['district'].unique() # find list of unique postcode\n",
    "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
    "\n",
    "    for i in range(0, len(district_geocode)):\n",
    "        result= geocoder.geocode(district_geocode[i])\n",
    "        if len(result) > 1:            \n",
    "            postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
    "        else:       \n",
    "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
    "\n",
    "            \n",
    "    return postcode_dict    \n",
    "\n",
    "def merge_district(postcode_dict, df):\n",
    "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()      \n",
    "    df_postcode.columns= ['district', 'postcode']\n",
    "    \n",
    "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
    "                                                         \n",
    "    df = df.merge(df_postcode, on='district')\n",
    "            \n",
    "    return  df\n",
    "\n",
    "def geocode_address(df):\n",
    "    key = os.getenv('OPENCAGE_API_KEY')\n",
    "    geocoder = OpenCageGeocode(key)\n",
    "\n",
    "    postcode_dict = {}\n",
    "    postcode_null = []\n",
    "    district_geocode = df['district'].unique() # find list of unique postcode\n",
    "    district_geocode = [s + ', Finland'  for s in district_geocode]\n",
    "\n",
    "    for i in range(0, len(district_geocode)):\n",
    "        result= geocoder.geocode(district_geocode[i])\n",
    "        if len(result) > 1:\n",
    "            try:\n",
    "                postcode_dict[district_geocode[i]]= result[1]['components']['postcode']\n",
    "            except :\n",
    "                print(district_geocode[i])\n",
    "                postcode_null.append(district_geocode[i])\n",
    "        else:       \n",
    "            postcode_dict[district_geocode[i]]= pd.DataFrame(result[0])['formatted'].iloc[0]\n",
    "      \n",
    "    return postcode_dict, postcode_null    \n",
    "\n",
    "\n",
    "def merge_district(postcode_dict, df):  \n",
    "    '''Merge 2 gecode dataframe so we have postcodes in transaction price'''\n",
    "    df_postcode = pd.DataFrame(postcode_dict, index=[0]).T.reset_index()   \n",
    "    df_postcode.columns= ['district', 'postcode']\n",
    "    \n",
    "    df_postcode['district'] = df_postcode['district'].str.replace(', Finland', '')\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda s: re.findall('\\d{5}', s) )\n",
    "    df_postcode['postcode'] = df_postcode['postcode'].map(lambda x: x[0] if len(x) >0 else None)\n",
    "                                                          \n",
    "    df= df.merge(df_postcode, on='district')\n",
    "    print('Geocode postcode for df transaction price: done')\n",
    "            \n",
    "    return  df\n",
    " \n",
    "def process_transaction_df():\n",
    "    df = clean_transaction_price()\n",
    "    postcode_geo, postcode_null = geocode_address(df) \n",
    "    df = merge_district(postcode_geo, df)\n",
    "    \n",
    "    df.to_csv('../../data/processed/transaction_price.csv', index=False)\n",
    "    print('==== Save df transaction price: done ====')\n",
    "       \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# clean asking price df\n",
    "# ============================================\n",
    "\n",
    "def clean_df_listing():\n",
    "    df = pd.read_csv(\"../data/raw/Espoo_Vantaa.csv\").drop_duplicates()\n",
    "    df['postcode'] = df['postcode'].astype(str).str.pad(5, \"left\", \"0\")\n",
    "    df['asking_price_m2'] = df['price'] / df['floor_area']\n",
    "\n",
    "    # clean municipality\n",
    "    df[\"municipality\"]=df[\"municipality\"].astype('category')\n",
    "    # number_of_room\n",
    "    df['number_of_room'] = df['house_info'].str.extract(pat =  \"(\\d\\s*m*h*\\s?\\+*)\")\n",
    "    df['number_of_room'] = df['number_of_room'].str.extract('(\\d+)')\n",
    "    df['number_of_room'] = df['number_of_room'].map(lambda x: float(x) if not pd.isna(x) else x)\n",
    "\n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: str(round(x)) if not pd.isna(x) else None)\n",
    "    df['number_of_room_cat'] = df['number_of_room'].map(lambda x: '3+' if float(x) >=3 else x)\n",
    "    df['number_of_room_cat'] = df['number_of_room_cat'].astype('str')\n",
    "    \n",
    "    # maitenance cost per sqm\n",
    "    df['maintenance_cost_m2'] = df['Unit maintenance cost'] / df['floor_area']\n",
    "    df['maintenance_cost_m2'] = df['maintenance_cost_m2'].map(lambda x: 0 if pd.isna(x) else x)\n",
    "    \n",
    "    # filter potential wrong values\n",
    "    df = df[ ~((df['number_of_room'] <1 )| (df['number_of_room'].isnull() )) ]\n",
    "    df = df[(df['asking_price_m2']>1)  &  (df['asking_price_m2']<20000)] # local knowledge: rarely there is \\\n",
    "                                                           # property sold with >20k/m2\n",
    "    # divide propery into 2 groups: house and apartment:\n",
    "    df['property_type_main'] = df['property_type'].map(lambda x: 'house' if x!='apartment' else x)\n",
    "    \n",
    "    df.to_csv('../data/processed/asking_price.csv', index=False)\n",
    "    print('==== Save df asking price: done ====')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================\n",
    "# clean rent df\n",
    "# ============================================\n",
    "\n",
    "def load_rent():\n",
    "    # load file\n",
    "    df = pd.read_json('../data/raw/rent.jl', lines=True,orient='records').drop_duplicates()\n",
    "    \n",
    "    # clean columns\n",
    "    df['postcode'] = df['postcode'].map(lambda x: re.sub('\\D+', '', x))\n",
    "    df['number_of_room'] = df['apartment_type'].map(lambda x: re.sub('h', '', x))\n",
    "    df = df.loc[df['number_of_room'].isin(['1', '2', '3+'])]\n",
    "    \n",
    "    # change dtype of rent columns\n",
    "    df[['nonsub_old', 'nonsub_new']] = df[['nonsub_old', 'nonsub_new']].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # drop unneeded columns:\n",
    "    df.drop(['apartment_type', 'ARA_rental'], axis=1, inplace=True)\n",
    "\n",
    "    df.to_csv('../data/processed/rent.csv', index=False)\n",
    "    print('==== Save df rent: done ====')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# merge df_rent, df_price and df_listing\n",
    "# ============================================\n",
    "\n",
    "def caculate_yield(x):\n",
    "    if x['new']:\n",
    "        x['net_yield'] = 12*(x['nonsub_new'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
    "    else:\n",
    "        x['net_yield']= 12*(x['nonsub_old'] - x['maintenance_cost_m2']) / x['asking_price_m2']\n",
    "    \n",
    "    x['net_yield']= np.round(x['net_yield'] * 100, 2)\n",
    "    \n",
    "    return x['net_yield']\n",
    "\n",
    "def merge_df(df_rent, df_listing, df_price):\n",
    "    # correct format of postcode:\n",
    "    for df in [df_rent, df_listing, df_price]:\n",
    "        df['postcode'] = df['postcode'].map(lambda x: str(np.int(x)) if not pd.isna(x) else x )\n",
    "        df['postcode'] = df['postcode'].astype(str).str.pad(width=5, side='left', fillchar='0')\n",
    "        if 'number_of_room_cat' in df.columns:\n",
    "            df['number_of_room_cat'] = df['number_of_room_cat'].replace({'1.0': '1' , '2.0':'2'})\n",
    "            \n",
    "    # merge price and listing\n",
    "\n",
    "    df_price = df_price.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
    "                ['price_m2'].mean().reset_index()\n",
    "    df_listing_agg = df_listing.groupby(['postcode', 'number_of_room_cat','property_type_main'])\\\n",
    "                ['asking_price_m2'].mean().reset_index()\n",
    "    \n",
    "    df_listing_price = df_listing_agg.merge(df_price[['postcode', 'number_of_room_cat','price_m2']], on=['postcode', 'number_of_room_cat'],\\\n",
    "                      how='left').drop_duplicates()\n",
    "    \n",
    "    # merge df listing and df rent\n",
    "    df_yield = df_listing.merge(df_rent, left_on = ['postcode', 'number_of_room_cat'], \\\n",
    "                            right_on = ['postcode', 'number_of_room'], how='left')\n",
    "   \n",
    "    print(df_yield['maintenance_cost_m2'].isnull().mean())\n",
    "    df_yield['new'] = df_yield['build_year'].map(lambda x: True if x >= 2015 else False)\n",
    "    df_yield['net_yield'] = df_yield.apply(caculate_yield, axis=1)\n",
    "    \n",
    "    df_yield.to_csv('../data/processed/df_yield.csv', index=False)\n",
    "    df_listing_price.to_csv('../data/processed/df_listing_price.csv', index=False)\n",
    "   \n",
    "    print('==== Save df yield and price: done ====')\n",
    "    \n",
    "    \n",
    "    return df_listing_price, df_yield\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Start')\n",
    "    # df_rent = load_rent()\n",
    "    df_price = process_transaction_df()\n",
    "    # df_listing = clean_df_listing()\n",
    "    # df_listing_price, df_yield =  merge_df(df_rent, df_listing, df_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Using cached geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Using cached pyproj-3.0.1.tar.gz (168 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\user\\anaconda3\\python.exe' 'C:\\Users\\user\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\user\\AppData\\Local\\Temp\\tmpbryh56_f'\n",
      "       cwd: C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-k21uhy5z\\pyproj\n",
      "  Complete output (1 lines):\n",
      "  proj executable not found. Please set the PROJ_DIR variable. For more information see: https://pyproj4.github.io/pyproj/stable/installation.html\n",
      "  ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\user\\anaconda3\\python.exe' 'C:\\Users\\user\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\user\\AppData\\Local\\Temp\\tmpbryh56_f' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
